{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time \n",
    "import datetime as datetime\n",
    "import glob\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1)\n",
    "import gym\n",
    "import gym_banana\n",
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>currency pair</th>\n",
       "      <th>timestamp</th>\n",
       "      <th>bid provider</th>\n",
       "      <th>bid price</th>\n",
       "      <th>bid volume</th>\n",
       "      <th>ask provider</th>\n",
       "      <th>ask price</th>\n",
       "      <th>ask volume</th>\n",
       "      <th>pad</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AUDUSD</td>\n",
       "      <td>02.01.2019 00:00:00</td>\n",
       "      <td>LP-3</td>\n",
       "      <td>0.72714</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72718</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AUDUSD</td>\n",
       "      <td>02.01.2019 00:00:01</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72712</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72717</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AUDUSD</td>\n",
       "      <td>02.01.2019 00:00:02</td>\n",
       "      <td>LP-1</td>\n",
       "      <td>0.72713</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72718</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AUDUSD</td>\n",
       "      <td>02.01.2019 00:00:03</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72713</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72717</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AUDUSD</td>\n",
       "      <td>02.01.2019 00:00:04</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72713</td>\n",
       "      <td>2000000.0</td>\n",
       "      <td>LP-2</td>\n",
       "      <td>0.72717</td>\n",
       "      <td>1000000.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  currency pair            timestamp bid provider  bid price  bid volume  \\\n",
       "0        AUDUSD  02.01.2019 00:00:00         LP-3    0.72714   1000000.0   \n",
       "1        AUDUSD  02.01.2019 00:00:01         LP-2    0.72712   2000000.0   \n",
       "2        AUDUSD  02.01.2019 00:00:02         LP-1    0.72713   1000000.0   \n",
       "3        AUDUSD  02.01.2019 00:00:03         LP-2    0.72713   1000000.0   \n",
       "4        AUDUSD  02.01.2019 00:00:04         LP-2    0.72713   2000000.0   \n",
       "\n",
       "  ask provider  ask price  ask volume  pad  \n",
       "0         LP-2    0.72718   2000000.0  0.0  \n",
       "1         LP-2    0.72717   2000000.0  0.0  \n",
       "2         LP-2    0.72718   2000000.0  0.0  \n",
       "3         LP-2    0.72717   2000000.0  0.0  \n",
       "4         LP-2    0.72717   1000000.0  0.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Pad = pd.read_csv('PadData_v2.csv')\n",
    "Pad.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The reward for episode No.1 is 0.04295500000004049\n"
     ]
    }
   ],
   "source": [
    "T = 3617\n",
    "m = 10\n",
    "to_draw = np.sort(Pad['timestamp'].unique())\n",
    "ccy = np.sort(Pad['currency pair'].unique())\n",
    "min_history = 500 # min episode length\n",
    "\n",
    "    \n",
    "def generate_episode(n,cur):\n",
    "    _max = to_draw.shape[0]\n",
    "    _end = min(n+T, _max)\n",
    "    timeframe = to_draw[n:_end]\n",
    "    other_bid = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    other_ask = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    i = 0\n",
    "    for elem in ccy:\n",
    "        tmp = Pad[Pad['currency pair'] == elem]\n",
    "        if elem == cur:\n",
    "            target_bid = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            target_ask = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "        else:\n",
    "            other_bid[:,i] = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            other_ask[:,i] = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "            i += 1\n",
    "    return target_bid, target_ask, other_bid, other_ask\n",
    "\n",
    "def features(price_path,m):\n",
    "    features = np.zeros((price_path.shape[0]-m,m))\n",
    "    for i in range(m):\n",
    "        features[:,i] = (np.log(price_path) - np.log(np.roll(price_path, i+1)))[m:]\n",
    "    return features\n",
    "\n",
    "def get_features(target_bid, target_ask, other_bid, other_ask, m):\n",
    "    feature_span = features(target_bid,m)\n",
    "    feature_span = np.append(feature_span, features(target_ask,m), axis = 1)\n",
    "    for i in range(other_bid.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_bid[:,i],m), axis = 1)\n",
    "    for j in range(other_ask.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_ask[:,j],m), axis = 1)\n",
    "    return feature_span\n",
    "\n",
    "def draw_episode(m, cur, min_history):\n",
    "    '''\n",
    "    Input:\n",
    "        m, number of lag returns z_1,...z_m\n",
    "        cur, currency pair that we target to trade\n",
    "        min_history, min length of a valid episode\n",
    "    '''\n",
    "#     n = np.random.randint(to_draw.shape[0] - min_history)\n",
    "    n = 1\n",
    "    target_bid, target_ask, other_bid, other_ask = generate_episode(n,cur)\n",
    "    feature_span = get_features(target_bid, target_ask, other_bid, other_ask, m)\n",
    "    return target_bid, target_ask, feature_span\n",
    "\n",
    "def calculate_reward(previous_action, current_action):\n",
    "    pass\n",
    "\n",
    "def draw_episode_with_episode_num(m, cur, min_history, n = None):\n",
    "    '''\n",
    "    Input:\n",
    "        m, number of lag returns z_1,...z_m\n",
    "        cur, currency pair that we target to trade\n",
    "        min_history, min length of a valid episode\n",
    "    '''\n",
    "    if n is None:\n",
    "        n = np.random.randint(to_draw.shape[0] - min_history)\n",
    "    \n",
    "    target_bid, target_ask, other_bid, other_ask = generate_episode(n,cur)\n",
    "    feature_span = get_features(target_bid, target_ask, other_bid, other_ask, m)\n",
    "    return target_bid, target_ask, feature_span\n",
    "    \n",
    "def test_policy(policy = None, episode=None, totalNumEpisodes=1):\n",
    "    if episode is None:\n",
    "        for i in range(totalNumEpisodes):\n",
    "            ask = np.zeros((1, 1))\n",
    "            bid = np.zeros((1,1 ))\n",
    "            previous_action = 0\n",
    "            reward_for_this_episode = 0\n",
    "            while ask.shape[0] <= 3600 and bid.shape[0]<=3600:\n",
    "                target_bid, target_ask, feature_span = draw_episode_with_episode_num(16, 'AUDUSD', 1000, 1)\n",
    "                bid, ask, features = target_bid[16:], target_ask[16:], feature_span\n",
    "            for t in range(3600):  # Don't infinite loop while learning\n",
    "                reward_for_this_episode += max(max(((ask[t+1] - ask[t]) + (bid[t+1] - bid[t]))/2, -((ask[t+1] - ask[t]) + (bid[t+1] - bid[t]))/2), 0)\n",
    "            print(\"The reward for episode No.{} is {}\".format(1, reward_for_this_episode))\n",
    "            \n",
    "        # a part of code to figure out the maximum value we can get\n",
    "                \n",
    "    else:\n",
    "        #run policy through episode\n",
    "        #compute\n",
    "        pass\n",
    "    \n",
    "def main():\n",
    "    test_policy()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-27 23:47:47,324 - root - INFO - BananaEnv - Version 0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:92: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "previous action tensor([0.3459, 0.3617, 0.2924], grad_fn=<SoftmaxBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -151.17071533203125\n",
      "================================================================================\n",
      "previous action tensor([9.9994e-01, 5.8457e-05, 1.3623e-08], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9480e-02,  2.7206e-02,  6.3803e-04, -8.4873e-05, -5.0561e-02,\n",
      "         -4.5311e-03, -1.0831e-03, -4.3460e-02, -7.4064e-03, -5.7956e-03,\n",
      "          5.4978e-03,  3.3733e-02, -4.7377e-05, -1.5012e-03,  1.7507e-02,\n",
      "          4.2726e-03],\n",
      "        [ 2.3353e-03, -1.6093e-03, -3.7748e-05,  5.0805e-06,  2.9907e-03,\n",
      "          2.6809e-04,  6.4044e-05,  2.5707e-03,  4.3813e-04,  3.4281e-04,\n",
      "         -3.2527e-04, -1.9954e-03,  2.8389e-06,  8.8769e-05, -1.0356e-03,\n",
      "         -2.5257e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2675,  0.3047, -0.1366,  0.5597,  0.4510, -0.0263, -0.3751,  0.3426,\n",
      "          0.1745, -0.3632,  0.3650,  0.3408,  0.4984, -0.3150, -0.0927, -0.0109],\n",
      "        [ 0.0821, -0.4265, -0.3988,  0.3057, -0.1318,  0.2745,  0.0320,  0.1845,\n",
      "          0.1236,  0.2043,  0.2786, -0.5204,  0.2829, -0.3951, -0.4240,  0.0342],\n",
      "        [-0.0961,  0.3303, -0.3254, -0.4996,  0.4085, -0.0834,  0.3161,  0.1802,\n",
      "         -0.4215,  0.1128,  0.1350, -0.3759, -0.2666,  0.1916,  0.1008, -0.2390]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2823.8349609375\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 3.2571e-09, 2.1922e-16], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2671,  0.3044, -0.1366,  0.5597,  0.4515, -0.0262, -0.3751,  0.3431,\n",
      "          0.1746, -0.3631,  0.3649,  0.3405,  0.4984, -0.3150, -0.0929, -0.0110],\n",
      "        [ 0.0820, -0.4264, -0.3988,  0.3057, -0.1318,  0.2745,  0.0320,  0.1845,\n",
      "          0.1236,  0.2043,  0.2786, -0.5204,  0.2829, -0.3951, -0.4240,  0.0342],\n",
      "        [-0.0965,  0.3306, -0.3254, -0.4996,  0.4080, -0.0834,  0.3161,  0.1798,\n",
      "         -0.4215,  0.1128,  0.1351, -0.3756, -0.2666,  0.1916,  0.1010, -0.2390]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 1.8147e-13, 3.5276e-24], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2667,  0.3041, -0.1366,  0.5597,  0.4520, -0.0262, -0.3751,  0.3435,\n",
      "          0.1746, -0.3631,  0.3648,  0.3401,  0.4984, -0.3150, -0.0930, -0.0110],\n",
      "        [ 0.0820, -0.4264, -0.3988,  0.3057, -0.1319,  0.2745,  0.0320,  0.1844,\n",
      "          0.1236,  0.2043,  0.2786, -0.5204,  0.2829, -0.3951, -0.4240,  0.0342],\n",
      "        [-0.0969,  0.3308, -0.3254, -0.4996,  0.4075, -0.0835,  0.3160,  0.1794,\n",
      "         -0.4216,  0.1127,  0.1351, -0.3753, -0.2666,  0.1916,  0.1012, -0.2389]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 1.0111e-17, 5.6764e-32], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2663,  0.3038, -0.1366,  0.5597,  0.4525, -0.0261, -0.3750,  0.3439,\n",
      "          0.1747, -0.3630,  0.3648,  0.3398,  0.4984, -0.3149, -0.0932, -0.0111],\n",
      "        [ 0.0820, -0.4264, -0.3988,  0.3057, -0.1319,  0.2745,  0.0320,  0.1844,\n",
      "          0.1235,  0.2043,  0.2786, -0.5203,  0.2829, -0.3951, -0.4240,  0.0342],\n",
      "        [-0.0972,  0.3311, -0.3254, -0.4996,  0.4071, -0.0835,  0.3160,  0.1790,\n",
      "         -0.4217,  0.1127,  0.1352, -0.3750, -0.2666,  0.1916,  0.1013, -0.2389]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 5.6334e-22, 9.1341e-40], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2660,  0.3036, -0.1366,  0.5597,  0.4530, -0.0261, -0.3750,  0.3444,\n",
      "          0.1748, -0.3630,  0.3647,  0.3395,  0.4984, -0.3149, -0.0934, -0.0111],\n",
      "        [ 0.0820, -0.4264, -0.3988,  0.3057, -0.1319,  0.2745,  0.0320,  0.1844,\n",
      "          0.1235,  0.2043,  0.2786, -0.5203,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0976,  0.3313, -0.3254, -0.4996,  0.4066, -0.0835,  0.3160,  0.1786,\n",
      "         -0.4217,  0.1126,  0.1352, -0.3747, -0.2666,  0.1915,  0.1015, -0.2388]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 3.1387e-26, 0.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2656,  0.3033, -0.1366,  0.5597,  0.4535, -0.0260, -0.3750,  0.3448,\n",
      "          0.1749, -0.3629,  0.3647,  0.3391,  0.4984, -0.3149, -0.0936, -0.0111],\n",
      "        [ 0.0819, -0.4264, -0.3988,  0.3057, -0.1320,  0.2745,  0.0320,  0.1844,\n",
      "          0.1235,  0.2043,  0.2786, -0.5203,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0980,  0.3316, -0.3254, -0.4996,  0.4061, -0.0836,  0.3160,  0.1782,\n",
      "         -0.4218,  0.1126,  0.1353, -0.3744, -0.2666,  0.1915,  0.1016, -0.2388]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 1.7487e-30, 0.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2652,  0.3030, -0.1366,  0.5597,  0.4540, -0.0260, -0.3750,  0.3452,\n",
      "          0.1749, -0.3629,  0.3646,  0.3388,  0.4984, -0.3149, -0.0937, -0.0112],\n",
      "        [ 0.0819, -0.4264, -0.3988,  0.3057, -0.1320,  0.2745,  0.0320,  0.1843,\n",
      "          0.1235,  0.2043,  0.2786, -0.5203,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0984,  0.3318, -0.3254, -0.4996,  0.4056, -0.0836,  0.3160,  0.1778,\n",
      "         -0.4219,  0.1125,  0.1353, -0.3740, -0.2666,  0.1915,  0.1018, -0.2388]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 9.7432e-35, 0.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2648,  0.3028, -0.1366,  0.5597,  0.4545, -0.0260, -0.3750,  0.3457,\n",
      "          0.1750, -0.3628,  0.3646,  0.3385,  0.4984, -0.3149, -0.0939, -0.0112],\n",
      "        [ 0.0819, -0.4263, -0.3988,  0.3057, -0.1320,  0.2745,  0.0320,  0.1843,\n",
      "          0.1235,  0.2043,  0.2786, -0.5203,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0987,  0.3321, -0.3254, -0.4996,  0.4052, -0.0837,  0.3160,  0.1774,\n",
      "         -0.4220,  0.1125,  0.1354, -0.3737, -0.2666,  0.1915,  0.1020, -0.2387]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 5.4285e-39, 0.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2644,  0.3025, -0.1367,  0.5597,  0.4550, -0.0259, -0.3750,  0.3461,\n",
      "          0.1751, -0.3627,  0.3645,  0.3381,  0.4984, -0.3149, -0.0941, -0.0113],\n",
      "        [ 0.0819, -0.4263, -0.3988,  0.3057, -0.1320,  0.2745,  0.0320,  0.1843,\n",
      "          0.1235,  0.2043,  0.2786, -0.5202,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0991,  0.3324, -0.3254, -0.4996,  0.4047, -0.0837,  0.3160,  0.1770,\n",
      "         -0.4220,  0.1124,  0.1354, -0.3734, -0.2666,  0.1915,  0.1021, -0.2387]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1.0000e+00, 3.0268e-43, 0.0000e+00], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2640,  0.3022, -0.1367,  0.5597,  0.4555, -0.0259, -0.3750,  0.3466,\n",
      "          0.1751, -0.3627,  0.3645,  0.3378,  0.4984, -0.3149, -0.0943, -0.0113],\n",
      "        [ 0.0818, -0.4263, -0.3988,  0.3057, -0.1321,  0.2745,  0.0320,  0.1843,\n",
      "          0.1235,  0.2043,  0.2786, -0.5202,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0995,  0.3326, -0.3254, -0.4996,  0.4042, -0.0838,  0.3160,  0.1766,\n",
      "         -0.4221,  0.1123,  0.1355, -0.3731, -0.2666,  0.1915,  0.1023, -0.2386]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2636,  0.3019, -0.1367,  0.5597,  0.4560, -0.0258, -0.3750,  0.3470,\n",
      "          0.1752, -0.3626,  0.3644,  0.3375,  0.4984, -0.3148, -0.0944, -0.0114],\n",
      "        [ 0.0818, -0.4263, -0.3988,  0.3057, -0.1321,  0.2745,  0.0320,  0.1842,\n",
      "          0.1235,  0.2043,  0.2786, -0.5202,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.0998,  0.3329, -0.3254, -0.4996,  0.4037, -0.0838,  0.3160,  0.1762,\n",
      "         -0.4222,  0.1123,  0.1355, -0.3728, -0.2666,  0.1915,  0.1025, -0.2386]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2632,  0.3017, -0.1367,  0.5597,  0.4565, -0.0258, -0.3750,  0.3474,\n",
      "          0.1753, -0.3626,  0.3644,  0.3371,  0.4984, -0.3148, -0.0946, -0.0114],\n",
      "        [ 0.0818, -0.4263, -0.3988,  0.3057, -0.1321,  0.2745,  0.0320,  0.1842,\n",
      "          0.1235,  0.2043,  0.2786, -0.5202,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.1002,  0.3331, -0.3254, -0.4996,  0.4033, -0.0838,  0.3160,  0.1758,\n",
      "         -0.4222,  0.1122,  0.1356, -0.3725, -0.2666,  0.1914,  0.1026, -0.2386]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2628,  0.3014, -0.1367,  0.5597,  0.4570, -0.0257, -0.3750,  0.3479,\n",
      "          0.1754, -0.3625,  0.3643,  0.3368,  0.4984, -0.3148, -0.0948, -0.0114],\n",
      "        [ 0.0818, -0.4263, -0.3988,  0.3057, -0.1322,  0.2745,  0.0320,  0.1842,\n",
      "          0.1235,  0.2043,  0.2786, -0.5202,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.1006,  0.3334, -0.3254, -0.4996,  0.4028, -0.0839,  0.3159,  0.1753,\n",
      "         -0.4223,  0.1122,  0.1357, -0.3721, -0.2666,  0.1914,  0.1028, -0.2385]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2624,  0.3011, -0.1367,  0.5597,  0.4575, -0.0257, -0.3749,  0.3483,\n",
      "          0.1754, -0.3624,  0.3642,  0.3364,  0.4984, -0.3148, -0.0950, -0.0115],\n",
      "        [ 0.0817, -0.4262, -0.3988,  0.3057, -0.1322,  0.2745,  0.0320,  0.1842,\n",
      "          0.1235,  0.2043,  0.2786, -0.5201,  0.2829, -0.3951, -0.4239,  0.0342],\n",
      "        [-0.1010,  0.3336, -0.3254, -0.4996,  0.4023, -0.0839,  0.3159,  0.1749,\n",
      "         -0.4224,  0.1121,  0.1357, -0.3718, -0.2666,  0.1914,  0.1030, -0.2385]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2620,  0.3009, -0.1367,  0.5597,  0.4580, -0.0256, -0.3749,  0.3487,\n",
      "          0.1755, -0.3624,  0.3642,  0.3361,  0.4984, -0.3148, -0.0951, -0.0115],\n",
      "        [ 0.0817, -0.4262, -0.3988,  0.3057, -0.1322,  0.2745,  0.0320,  0.1841,\n",
      "          0.1235,  0.2043,  0.2786, -0.5201,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1013,  0.3339, -0.3254, -0.4996,  0.4018, -0.0840,  0.3159,  0.1745,\n",
      "         -0.4224,  0.1121,  0.1358, -0.3715, -0.2666,  0.1914,  0.1031, -0.2384]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2616,  0.3006, -0.1367,  0.5597,  0.4585, -0.0256, -0.3749,  0.3492,\n",
      "          0.1756, -0.3623,  0.3641,  0.3358,  0.4984, -0.3148, -0.0953, -0.0116],\n",
      "        [ 0.0817, -0.4262, -0.3988,  0.3057, -0.1323,  0.2745,  0.0320,  0.1841,\n",
      "          0.1235,  0.2043,  0.2786, -0.5201,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1017,  0.3341, -0.3254, -0.4996,  0.4014, -0.0840,  0.3159,  0.1741,\n",
      "         -0.4225,  0.1120,  0.1358, -0.3712, -0.2666,  0.1914,  0.1033, -0.2384]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2612,  0.3003, -0.1367,  0.5597,  0.4591, -0.0255, -0.3749,  0.3496,\n",
      "          0.1757, -0.3623,  0.3641,  0.3354,  0.4984, -0.3148, -0.0955, -0.0116],\n",
      "        [ 0.0817, -0.4262, -0.3988,  0.3057, -0.1323,  0.2745,  0.0320,  0.1841,\n",
      "          0.1235,  0.2043,  0.2786, -0.5201,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1021,  0.3344, -0.3253, -0.4996,  0.4009, -0.0841,  0.3159,  0.1737,\n",
      "         -0.4226,  0.1120,  0.1359, -0.3709, -0.2666,  0.1914,  0.1035, -0.2384]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2608,  0.3000, -0.1367,  0.5597,  0.4596, -0.0255, -0.3749,  0.3500,\n",
      "          0.1757, -0.3622,  0.3640,  0.3351,  0.4984, -0.3147, -0.0957, -0.0117],\n",
      "        [ 0.0817, -0.4262, -0.3988,  0.3057, -0.1323,  0.2745,  0.0320,  0.1840,\n",
      "          0.1235,  0.2043,  0.2786, -0.5201,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1024,  0.3347, -0.3253, -0.4996,  0.4004, -0.0841,  0.3159,  0.1733,\n",
      "         -0.4226,  0.1119,  0.1359, -0.3705, -0.2666,  0.1914,  0.1036, -0.2383]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2604,  0.2998, -0.1367,  0.5597,  0.4601, -0.0255, -0.3749,  0.3505,\n",
      "          0.1758, -0.3622,  0.3640,  0.3348,  0.4984, -0.3147, -0.0958, -0.0117],\n",
      "        [ 0.0816, -0.4262, -0.3988,  0.3057, -0.1323,  0.2744,  0.0320,  0.1840,\n",
      "          0.1235,  0.2043,  0.2786, -0.5200,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1028,  0.3349, -0.3253, -0.4996,  0.3999, -0.0841,  0.3159,  0.1729,\n",
      "         -0.4227,  0.1119,  0.1360, -0.3702, -0.2666,  0.1913,  0.1038, -0.2383]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2600,  0.2995, -0.1367,  0.5597,  0.4606, -0.0254, -0.3749,  0.3509,\n",
      "          0.1759, -0.3621,  0.3639,  0.3344,  0.4984, -0.3147, -0.0960, -0.0117],\n",
      "        [ 0.0816, -0.4262, -0.3988,  0.3057, -0.1324,  0.2744,  0.0320,  0.1840,\n",
      "          0.1235,  0.2043,  0.2786, -0.5200,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1032,  0.3352, -0.3253, -0.4996,  0.3995, -0.0842,  0.3159,  0.1725,\n",
      "         -0.4228,  0.1118,  0.1360, -0.3699, -0.2666,  0.1913,  0.1040, -0.2382]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2596,  0.2992, -0.1367,  0.5597,  0.4611, -0.0254, -0.3749,  0.3513,\n",
      "          0.1760, -0.3620,  0.3639,  0.3341,  0.4984, -0.3147, -0.0962, -0.0118],\n",
      "        [ 0.0816, -0.4261, -0.3988,  0.3057, -0.1324,  0.2744,  0.0320,  0.1840,\n",
      "          0.1235,  0.2043,  0.2786, -0.5200,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1036,  0.3354, -0.3253, -0.4996,  0.3990, -0.0842,  0.3159,  0.1721,\n",
      "         -0.4229,  0.1117,  0.1361, -0.3696, -0.2666,  0.1913,  0.1041, -0.2382]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2592,  0.2989, -0.1367,  0.5597,  0.4616, -0.0253, -0.3749,  0.3518,\n",
      "          0.1760, -0.3620,  0.3638,  0.3337,  0.4984, -0.3147, -0.0964, -0.0118],\n",
      "        [ 0.0816, -0.4261, -0.3988,  0.3057, -0.1324,  0.2744,  0.0320,  0.1839,\n",
      "          0.1235,  0.2042,  0.2786, -0.5200,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1039,  0.3357, -0.3253, -0.4996,  0.3985, -0.0843,  0.3158,  0.1717,\n",
      "         -0.4229,  0.1117,  0.1361, -0.3693, -0.2666,  0.1913,  0.1043, -0.2382]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2588,  0.2987, -0.1367,  0.5598,  0.4621, -0.0253, -0.3748,  0.3522,\n",
      "          0.1761, -0.3619,  0.3637,  0.3334,  0.4984, -0.3147, -0.0965, -0.0119],\n",
      "        [ 0.0815, -0.4261, -0.3988,  0.3057, -0.1325,  0.2744,  0.0320,  0.1839,\n",
      "          0.1235,  0.2042,  0.2786, -0.5200,  0.2829, -0.3951, -0.4238,  0.0342],\n",
      "        [-0.1043,  0.3359, -0.3253, -0.4996,  0.3980, -0.0843,  0.3158,  0.1713,\n",
      "         -0.4230,  0.1116,  0.1362, -0.3690, -0.2666,  0.1913,  0.1044, -0.2381]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2585,  0.2984, -0.1368,  0.5598,  0.4626, -0.0252, -0.3748,  0.3526,\n",
      "          0.1762, -0.3619,  0.3637,  0.3331,  0.4984, -0.3146, -0.0967, -0.0119],\n",
      "        [ 0.0815, -0.4261, -0.3988,  0.3057, -0.1325,  0.2744,  0.0320,  0.1839,\n",
      "          0.1235,  0.2042,  0.2786, -0.5199,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1047,  0.3362, -0.3253, -0.4996,  0.3976, -0.0844,  0.3158,  0.1708,\n",
      "         -0.4231,  0.1116,  0.1362, -0.3686, -0.2666,  0.1913,  0.1046, -0.2381]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2581,  0.2981, -0.1368,  0.5598,  0.4631, -0.0252, -0.3748,  0.3531,\n",
      "          0.1763, -0.3618,  0.3636,  0.3327,  0.4984, -0.3146, -0.0969, -0.0120],\n",
      "        [ 0.0815, -0.4261, -0.3988,  0.3057, -0.1325,  0.2744,  0.0320,  0.1839,\n",
      "          0.1235,  0.2042,  0.2786, -0.5199,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1050,  0.3364, -0.3253, -0.4996,  0.3971, -0.0844,  0.3158,  0.1704,\n",
      "         -0.4231,  0.1115,  0.1363, -0.3683, -0.2666,  0.1913,  0.1048, -0.2380]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2577,  0.2979, -0.1368,  0.5598,  0.4636, -0.0251, -0.3748,  0.3535,\n",
      "          0.1763, -0.3617,  0.3636,  0.3324,  0.4984, -0.3146, -0.0971, -0.0120],\n",
      "        [ 0.0815, -0.4261, -0.3988,  0.3057, -0.1326,  0.2744,  0.0320,  0.1838,\n",
      "          0.1235,  0.2042,  0.2786, -0.5199,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1054,  0.3367, -0.3253, -0.4996,  0.3966, -0.0844,  0.3158,  0.1700,\n",
      "         -0.4232,  0.1115,  0.1363, -0.3680, -0.2666,  0.1912,  0.1049, -0.2380]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2573,  0.2976, -0.1368,  0.5598,  0.4641, -0.0251, -0.3748,  0.3539,\n",
      "          0.1764, -0.3617,  0.3635,  0.3321,  0.4984, -0.3146, -0.0972, -0.0120],\n",
      "        [ 0.0814, -0.4260, -0.3988,  0.3057, -0.1326,  0.2744,  0.0320,  0.1838,\n",
      "          0.1234,  0.2042,  0.2787, -0.5199,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1058,  0.3370, -0.3253, -0.4996,  0.3961, -0.0845,  0.3158,  0.1696,\n",
      "         -0.4233,  0.1114,  0.1364, -0.3677, -0.2666,  0.1912,  0.1051, -0.2380]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2569,  0.2973, -0.1368,  0.5598,  0.4646, -0.0250, -0.3748,  0.3544,\n",
      "          0.1765, -0.3616,  0.3635,  0.3317,  0.4984, -0.3146, -0.0974, -0.0121],\n",
      "        [ 0.0814, -0.4260, -0.3988,  0.3057, -0.1326,  0.2744,  0.0320,  0.1838,\n",
      "          0.1234,  0.2042,  0.2787, -0.5199,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1062,  0.3372, -0.3253, -0.4996,  0.3957, -0.0845,  0.3158,  0.1692,\n",
      "         -0.4233,  0.1114,  0.1364, -0.3674, -0.2666,  0.1912,  0.1053, -0.2379]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2565,  0.2970, -0.1368,  0.5598,  0.4651, -0.0250, -0.3748,  0.3548,\n",
      "          0.1766, -0.3616,  0.3634,  0.3314,  0.4984, -0.3146, -0.0976, -0.0121],\n",
      "        [ 0.0814, -0.4260, -0.3988,  0.3057, -0.1326,  0.2744,  0.0320,  0.1838,\n",
      "          0.1234,  0.2042,  0.2787, -0.5198,  0.2829, -0.3951, -0.4237,  0.0342],\n",
      "        [-0.1065,  0.3375, -0.3253, -0.4996,  0.3952, -0.0846,  0.3158,  0.1688,\n",
      "         -0.4234,  0.1113,  0.1365, -0.3671, -0.2666,  0.1912,  0.1054, -0.2379]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2561,  0.2968, -0.1368,  0.5598,  0.4656, -0.0250, -0.3748,  0.3552,\n",
      "          0.1766, -0.3615,  0.3634,  0.3310,  0.4984, -0.3146, -0.0978, -0.0122],\n",
      "        [ 0.0814, -0.4260, -0.3988,  0.3057, -0.1327,  0.2744,  0.0320,  0.1837,\n",
      "          0.1234,  0.2042,  0.2787, -0.5198,  0.2829, -0.3951, -0.4237,  0.0343],\n",
      "        [-0.1069,  0.3377, -0.3253, -0.4996,  0.3947, -0.0846,  0.3158,  0.1684,\n",
      "         -0.4235,  0.1113,  0.1365, -0.3667, -0.2666,  0.1912,  0.1056, -0.2378]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2557,  0.2965, -0.1368,  0.5598,  0.4661, -0.0249, -0.3748,  0.3557,\n",
      "          0.1767, -0.3615,  0.3633,  0.3307,  0.4984, -0.3145, -0.0979, -0.0122],\n",
      "        [ 0.0814, -0.4260, -0.3988,  0.3057, -0.1327,  0.2744,  0.0320,  0.1837,\n",
      "          0.1234,  0.2042,  0.2787, -0.5198,  0.2829, -0.3951, -0.4237,  0.0343],\n",
      "        [-0.1073,  0.3380, -0.3253, -0.4996,  0.3942, -0.0846,  0.3158,  0.1680,\n",
      "         -0.4236,  0.1112,  0.1366, -0.3664, -0.2666,  0.1912,  0.1058, -0.2378]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2553,  0.2962, -0.1368,  0.5598,  0.4666, -0.0249, -0.3747,  0.3561,\n",
      "          0.1768, -0.3614,  0.3633,  0.3304,  0.4984, -0.3145, -0.0981, -0.0123],\n",
      "        [ 0.0813, -0.4260, -0.3988,  0.3057, -0.1327,  0.2744,  0.0320,  0.1837,\n",
      "          0.1234,  0.2042,  0.2787, -0.5198,  0.2829, -0.3951, -0.4237,  0.0343],\n",
      "        [-0.1076,  0.3382, -0.3253, -0.4996,  0.3937, -0.0847,  0.3157,  0.1676,\n",
      "         -0.4236,  0.1112,  0.1366, -0.3661, -0.2666,  0.1912,  0.1059, -0.2378]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2549,  0.2960, -0.1368,  0.5598,  0.4671, -0.0248, -0.3747,  0.3566,\n",
      "          0.1769, -0.3613,  0.3632,  0.3300,  0.4984, -0.3145, -0.0983, -0.0123],\n",
      "        [ 0.0813, -0.4259, -0.3988,  0.3057, -0.1328,  0.2744,  0.0320,  0.1837,\n",
      "          0.1234,  0.2042,  0.2787, -0.5198,  0.2829, -0.3952, -0.4237,  0.0343],\n",
      "        [-0.1080,  0.3385, -0.3252, -0.4996,  0.3933, -0.0847,  0.3157,  0.1672,\n",
      "         -0.4237,  0.1111,  0.1367, -0.3658, -0.2666,  0.1911,  0.1061, -0.2377]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2545,  0.2957, -0.1368,  0.5598,  0.4676, -0.0248, -0.3747,  0.3570,\n",
      "          0.1769, -0.3613,  0.3631,  0.3297,  0.4984, -0.3145, -0.0985, -0.0123],\n",
      "        [ 0.0813, -0.4259, -0.3988,  0.3057, -0.1328,  0.2744,  0.0320,  0.1836,\n",
      "          0.1234,  0.2042,  0.2787, -0.5197,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1084,  0.3388, -0.3252, -0.4996,  0.3928, -0.0848,  0.3157,  0.1668,\n",
      "         -0.4238,  0.1110,  0.1367, -0.3655, -0.2666,  0.1911,  0.1063, -0.2377]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2541,  0.2954, -0.1368,  0.5598,  0.4682, -0.0247, -0.3747,  0.3574,\n",
      "          0.1770, -0.3612,  0.3631,  0.3294,  0.4984, -0.3145, -0.0986, -0.0124],\n",
      "        [ 0.0813, -0.4259, -0.3988,  0.3057, -0.1328,  0.2744,  0.0320,  0.1836,\n",
      "          0.1234,  0.2042,  0.2787, -0.5197,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1088,  0.3390, -0.3252, -0.4996,  0.3923, -0.0848,  0.3157,  0.1663,\n",
      "         -0.4238,  0.1110,  0.1368, -0.3652, -0.2666,  0.1911,  0.1064, -0.2376]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2537,  0.2951, -0.1368,  0.5598,  0.4687, -0.0247, -0.3747,  0.3579,\n",
      "          0.1771, -0.3612,  0.3630,  0.3290,  0.4984, -0.3145, -0.0988, -0.0124],\n",
      "        [ 0.0812, -0.4259, -0.3988,  0.3057, -0.1329,  0.2744,  0.0320,  0.1836,\n",
      "          0.1234,  0.2042,  0.2787, -0.5197,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1091,  0.3393, -0.3252, -0.4996,  0.3918, -0.0849,  0.3157,  0.1659,\n",
      "         -0.4239,  0.1109,  0.1368, -0.3648, -0.2666,  0.1911,  0.1066, -0.2376]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2533,  0.2949, -0.1368,  0.5598,  0.4692, -0.0246, -0.3747,  0.3583,\n",
      "          0.1771, -0.3611,  0.3630,  0.3287,  0.4984, -0.3145, -0.0990, -0.0125],\n",
      "        [ 0.0812, -0.4259, -0.3988,  0.3057, -0.1329,  0.2744,  0.0320,  0.1836,\n",
      "          0.1234,  0.2042,  0.2787, -0.5197,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1095,  0.3395, -0.3252, -0.4996,  0.3914, -0.0849,  0.3157,  0.1655,\n",
      "         -0.4240,  0.1109,  0.1369, -0.3645, -0.2666,  0.1911,  0.1068, -0.2376]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2529,  0.2946, -0.1368,  0.5598,  0.4697, -0.0246, -0.3747,  0.3587,\n",
      "          0.1772, -0.3611,  0.3629,  0.3283,  0.4984, -0.3144, -0.0992, -0.0125],\n",
      "        [ 0.0812, -0.4259, -0.3988,  0.3057, -0.1329,  0.2744,  0.0320,  0.1835,\n",
      "          0.1234,  0.2042,  0.2787, -0.5197,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1099,  0.3398, -0.3252, -0.4996,  0.3909, -0.0849,  0.3157,  0.1651,\n",
      "         -0.4240,  0.1108,  0.1369, -0.3642, -0.2666,  0.1911,  0.1069, -0.2375]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2525,  0.2943, -0.1368,  0.5598,  0.4702, -0.0245, -0.3747,  0.3592,\n",
      "          0.1773, -0.3610,  0.3629,  0.3280,  0.4984, -0.3144, -0.0993, -0.0126],\n",
      "        [ 0.0812, -0.4258, -0.3988,  0.3057, -0.1329,  0.2744,  0.0320,  0.1835,\n",
      "          0.1234,  0.2042,  0.2787, -0.5196,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1102,  0.3400, -0.3252, -0.4996,  0.3904, -0.0850,  0.3157,  0.1647,\n",
      "         -0.4241,  0.1108,  0.1370, -0.3639, -0.2666,  0.1911,  0.1071, -0.2375]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2521,  0.2940, -0.1369,  0.5598,  0.4707, -0.0245, -0.3747,  0.3596,\n",
      "          0.1774, -0.3609,  0.3628,  0.3277,  0.4984, -0.3144, -0.0995, -0.0126],\n",
      "        [ 0.0811, -0.4258, -0.3988,  0.3057, -0.1330,  0.2744,  0.0320,  0.1835,\n",
      "          0.1234,  0.2042,  0.2787, -0.5196,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1106,  0.3403, -0.3252, -0.4996,  0.3899, -0.0850,  0.3157,  0.1643,\n",
      "         -0.4242,  0.1107,  0.1370, -0.3636, -0.2666,  0.1910,  0.1072, -0.2374]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2517,  0.2938, -0.1369,  0.5598,  0.4712, -0.0245, -0.3746,  0.3600,\n",
      "          0.1774, -0.3609,  0.3628,  0.3273,  0.4984, -0.3144, -0.0997, -0.0126],\n",
      "        [ 0.0811, -0.4258, -0.3988,  0.3057, -0.1330,  0.2744,  0.0320,  0.1835,\n",
      "          0.1234,  0.2042,  0.2787, -0.5196,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1110,  0.3405, -0.3252, -0.4996,  0.3895, -0.0851,  0.3157,  0.1639,\n",
      "         -0.4243,  0.1107,  0.1371, -0.3632, -0.2666,  0.1910,  0.1074, -0.2374]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2513,  0.2935, -0.1369,  0.5598,  0.4717, -0.0244, -0.3746,  0.3605,\n",
      "          0.1775, -0.3608,  0.3627,  0.3270,  0.4984, -0.3144, -0.0999, -0.0127],\n",
      "        [ 0.0811, -0.4258, -0.3988,  0.3057, -0.1330,  0.2744,  0.0320,  0.1834,\n",
      "          0.1234,  0.2042,  0.2787, -0.5196,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1114,  0.3408, -0.3252, -0.4996,  0.3890, -0.0851,  0.3156,  0.1635,\n",
      "         -0.4243,  0.1106,  0.1372, -0.3629, -0.2666,  0.1910,  0.1076, -0.2374]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2509,  0.2932, -0.1369,  0.5598,  0.4722, -0.0244, -0.3746,  0.3609,\n",
      "          0.1776, -0.3608,  0.3626,  0.3267,  0.4984, -0.3144, -0.1000, -0.0127],\n",
      "        [ 0.0811, -0.4258, -0.3988,  0.3057, -0.1331,  0.2744,  0.0320,  0.1834,\n",
      "          0.1234,  0.2042,  0.2787, -0.5196,  0.2829, -0.3952, -0.4236,  0.0343],\n",
      "        [-0.1117,  0.3411, -0.3252, -0.4996,  0.3885, -0.0852,  0.3156,  0.1631,\n",
      "         -0.4244,  0.1106,  0.1372, -0.3626, -0.2666,  0.1910,  0.1077, -0.2373]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2506,  0.2930, -0.1369,  0.5598,  0.4727, -0.0243, -0.3746,  0.3613,\n",
      "          0.1777, -0.3607,  0.3626,  0.3263,  0.4984, -0.3143, -0.1002, -0.0128],\n",
      "        [ 0.0810, -0.4258, -0.3988,  0.3057, -0.1331,  0.2744,  0.0320,  0.1834,\n",
      "          0.1234,  0.2042,  0.2787, -0.5195,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1121,  0.3413, -0.3252, -0.4996,  0.3880, -0.0852,  0.3156,  0.1627,\n",
      "         -0.4245,  0.1105,  0.1373, -0.3623, -0.2667,  0.1910,  0.1079, -0.2373]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2502,  0.2927, -0.1369,  0.5598,  0.4732, -0.0243, -0.3746,  0.3618,\n",
      "          0.1777, -0.3606,  0.3625,  0.3260,  0.4984, -0.3143, -0.1004, -0.0128],\n",
      "        [ 0.0810, -0.4257, -0.3988,  0.3057, -0.1331,  0.2744,  0.0320,  0.1834,\n",
      "          0.1234,  0.2042,  0.2787, -0.5195,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1125,  0.3416, -0.3252, -0.4996,  0.3876, -0.0852,  0.3156,  0.1623,\n",
      "         -0.4245,  0.1104,  0.1373, -0.3620, -0.2667,  0.1910,  0.1081, -0.2372]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2498,  0.2924, -0.1369,  0.5598,  0.4737, -0.0242, -0.3746,  0.3622,\n",
      "          0.1778, -0.3606,  0.3625,  0.3256,  0.4984, -0.3143, -0.1006, -0.0129],\n",
      "        [ 0.0810, -0.4257, -0.3988,  0.3057, -0.1332,  0.2744,  0.0320,  0.1833,\n",
      "          0.1234,  0.2042,  0.2787, -0.5195,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1128,  0.3418, -0.3252, -0.4996,  0.3871, -0.0853,  0.3156,  0.1618,\n",
      "         -0.4246,  0.1104,  0.1374, -0.3617, -0.2667,  0.1910,  0.1082, -0.2372]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2494,  0.2921, -0.1369,  0.5598,  0.4742, -0.0242, -0.3746,  0.3626,\n",
      "          0.1779, -0.3605,  0.3624,  0.3253,  0.4984, -0.3143, -0.1007, -0.0129],\n",
      "        [ 0.0810, -0.4257, -0.3988,  0.3057, -0.1332,  0.2744,  0.0320,  0.1833,\n",
      "          0.1234,  0.2042,  0.2787, -0.5195,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1132,  0.3421, -0.3252, -0.4996,  0.3866, -0.0853,  0.3156,  0.1614,\n",
      "         -0.4247,  0.1103,  0.1374, -0.3613, -0.2667,  0.1909,  0.1084, -0.2371]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2490,  0.2919, -0.1369,  0.5598,  0.4747, -0.0241, -0.3746,  0.3631,\n",
      "          0.1780, -0.3605,  0.3624,  0.3250,  0.4984, -0.3143, -0.1009, -0.0129],\n",
      "        [ 0.0810, -0.4257, -0.3988,  0.3057, -0.1332,  0.2744,  0.0320,  0.1833,\n",
      "          0.1234,  0.2042,  0.2787, -0.5195,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1136,  0.3423, -0.3252, -0.4996,  0.3861, -0.0854,  0.3156,  0.1610,\n",
      "         -0.4247,  0.1103,  0.1375, -0.3610, -0.2667,  0.1909,  0.1086, -0.2371]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2486,  0.2916, -0.1369,  0.5598,  0.4752, -0.0241, -0.3746,  0.3635,\n",
      "          0.1780, -0.3604,  0.3623,  0.3246,  0.4984, -0.3143, -0.1011, -0.0130],\n",
      "        [ 0.0809, -0.4257, -0.3988,  0.3057, -0.1332,  0.2744,  0.0320,  0.1833,\n",
      "          0.1234,  0.2042,  0.2787, -0.5194,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1140,  0.3426, -0.3252, -0.4996,  0.3857, -0.0854,  0.3156,  0.1606,\n",
      "         -0.4248,  0.1102,  0.1375, -0.3607, -0.2667,  0.1909,  0.1087, -0.2371]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2482,  0.2913, -0.1369,  0.5598,  0.4757, -0.0240, -0.3746,  0.3639,\n",
      "          0.1781, -0.3604,  0.3623,  0.3243,  0.4984, -0.3143, -0.1013, -0.0130],\n",
      "        [ 0.0809, -0.4257, -0.3988,  0.3057, -0.1333,  0.2744,  0.0320,  0.1832,\n",
      "          0.1233,  0.2042,  0.2787, -0.5194,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1143,  0.3428, -0.3251, -0.4996,  0.3852, -0.0855,  0.3156,  0.1602,\n",
      "         -0.4249,  0.1102,  0.1376, -0.3604, -0.2667,  0.1909,  0.1089, -0.2370]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2478,  0.2911, -0.1369,  0.5598,  0.4762, -0.0240, -0.3745,  0.3644,\n",
      "          0.1782, -0.3603,  0.3622,  0.3240,  0.4984, -0.3142, -0.1014, -0.0131],\n",
      "        [ 0.0809, -0.4257, -0.3988,  0.3057, -0.1333,  0.2744,  0.0320,  0.1832,\n",
      "          0.1233,  0.2041,  0.2787, -0.5194,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1147,  0.3431, -0.3251, -0.4996,  0.3847, -0.0855,  0.3156,  0.1598,\n",
      "         -0.4249,  0.1101,  0.1376, -0.3601, -0.2667,  0.1909,  0.1091, -0.2370]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2474,  0.2908, -0.1369,  0.5598,  0.4767, -0.0240, -0.3745,  0.3648,\n",
      "          0.1783, -0.3602,  0.3622,  0.3236,  0.4984, -0.3142, -0.1016, -0.0131],\n",
      "        [ 0.0809, -0.4256, -0.3988,  0.3057, -0.1333,  0.2744,  0.0320,  0.1832,\n",
      "          0.1233,  0.2041,  0.2787, -0.5194,  0.2829, -0.3952, -0.4235,  0.0343],\n",
      "        [-0.1151,  0.3434, -0.3251, -0.4996,  0.3842, -0.0855,  0.3155,  0.1594,\n",
      "         -0.4250,  0.1101,  0.1377, -0.3598, -0.2667,  0.1909,  0.1092, -0.2369]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2470,  0.2905, -0.1369,  0.5598,  0.4773, -0.0239, -0.3745,  0.3652,\n",
      "          0.1783, -0.3602,  0.3621,  0.3233,  0.4984, -0.3142, -0.1018, -0.0132],\n",
      "        [ 0.0808, -0.4256, -0.3988,  0.3057, -0.1334,  0.2744,  0.0320,  0.1831,\n",
      "          0.1233,  0.2041,  0.2787, -0.5194,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1154,  0.3436, -0.3251, -0.4996,  0.3838, -0.0856,  0.3155,  0.1590,\n",
      "         -0.4251,  0.1100,  0.1377, -0.3594, -0.2667,  0.1909,  0.1094, -0.2369]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2466,  0.2902, -0.1369,  0.5598,  0.4778, -0.0239, -0.3745,  0.3657,\n",
      "          0.1784, -0.3601,  0.3620,  0.3229,  0.4984, -0.3142, -0.1020, -0.0132],\n",
      "        [ 0.0808, -0.4256, -0.3988,  0.3057, -0.1334,  0.2744,  0.0320,  0.1831,\n",
      "          0.1233,  0.2041,  0.2787, -0.5193,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1158,  0.3439, -0.3251, -0.4996,  0.3833, -0.0856,  0.3155,  0.1586,\n",
      "         -0.4252,  0.1100,  0.1378, -0.3591, -0.2667,  0.1908,  0.1096, -0.2369]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2462,  0.2900, -0.1369,  0.5598,  0.4783, -0.0238, -0.3745,  0.3661,\n",
      "          0.1785, -0.3601,  0.3620,  0.3226,  0.4984, -0.3142, -0.1021, -0.0132],\n",
      "        [ 0.0808, -0.4256, -0.3988,  0.3057, -0.1334,  0.2744,  0.0320,  0.1831,\n",
      "          0.1233,  0.2041,  0.2787, -0.5193,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1162,  0.3441, -0.3251, -0.4996,  0.3828, -0.0857,  0.3155,  0.1582,\n",
      "         -0.4252,  0.1099,  0.1378, -0.3588, -0.2667,  0.1908,  0.1097, -0.2368]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2458,  0.2897, -0.1370,  0.5598,  0.4788, -0.0238, -0.3745,  0.3665,\n",
      "          0.1786, -0.3600,  0.3619,  0.3223,  0.4984, -0.3142, -0.1023, -0.0133],\n",
      "        [ 0.0808, -0.4256, -0.3988,  0.3057, -0.1335,  0.2743,  0.0320,  0.1831,\n",
      "          0.1233,  0.2041,  0.2787, -0.5193,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1166,  0.3444, -0.3251, -0.4996,  0.3823, -0.0857,  0.3155,  0.1578,\n",
      "         -0.4253,  0.1098,  0.1379, -0.3585, -0.2667,  0.1908,  0.1099, -0.2368]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2454,  0.2894, -0.1370,  0.5598,  0.4793, -0.0237, -0.3745,  0.3670,\n",
      "          0.1786, -0.3600,  0.3619,  0.3219,  0.4984, -0.3142, -0.1025, -0.0133],\n",
      "        [ 0.0807, -0.4256, -0.3988,  0.3057, -0.1335,  0.2743,  0.0320,  0.1830,\n",
      "          0.1233,  0.2041,  0.2788, -0.5193,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1169,  0.3446, -0.3251, -0.4996,  0.3819, -0.0858,  0.3155,  0.1574,\n",
      "         -0.4254,  0.1098,  0.1379, -0.3582, -0.2667,  0.1908,  0.1100, -0.2367]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2450,  0.2892, -0.1370,  0.5598,  0.4798, -0.0237, -0.3745,  0.3674,\n",
      "          0.1787, -0.3599,  0.3618,  0.3216,  0.4984, -0.3141, -0.1027, -0.0134],\n",
      "        [ 0.0807, -0.4255, -0.3988,  0.3057, -0.1335,  0.2743,  0.0320,  0.1830,\n",
      "          0.1233,  0.2041,  0.2788, -0.5193,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1173,  0.3449, -0.3251, -0.4996,  0.3814, -0.0858,  0.3155,  0.1569,\n",
      "         -0.4254,  0.1097,  0.1380, -0.3579, -0.2667,  0.1908,  0.1102, -0.2367]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2446,  0.2889, -0.1370,  0.5598,  0.4803, -0.0236, -0.3745,  0.3679,\n",
      "          0.1788, -0.3598,  0.3618,  0.3213,  0.4984, -0.3141, -0.1028, -0.0134],\n",
      "        [ 0.0807, -0.4255, -0.3988,  0.3057, -0.1335,  0.2743,  0.0320,  0.1830,\n",
      "          0.1233,  0.2041,  0.2788, -0.5192,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1177,  0.3451, -0.3251, -0.4996,  0.3809, -0.0858,  0.3155,  0.1565,\n",
      "         -0.4255,  0.1097,  0.1380, -0.3575, -0.2667,  0.1908,  0.1104, -0.2367]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2442,  0.2886, -0.1370,  0.5598,  0.4808, -0.0236, -0.3744,  0.3683,\n",
      "          0.1789, -0.3598,  0.3617,  0.3209,  0.4984, -0.3141, -0.1030, -0.0135],\n",
      "        [ 0.0807, -0.4255, -0.3988,  0.3057, -0.1336,  0.2743,  0.0320,  0.1830,\n",
      "          0.1233,  0.2041,  0.2788, -0.5192,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1180,  0.3454, -0.3251, -0.4996,  0.3804, -0.0859,  0.3155,  0.1561,\n",
      "         -0.4256,  0.1096,  0.1381, -0.3572, -0.2667,  0.1908,  0.1105, -0.2366]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2438,  0.2883, -0.1370,  0.5598,  0.4813, -0.0235, -0.3744,  0.3687,\n",
      "          0.1789, -0.3597,  0.3617,  0.3206,  0.4984, -0.3141, -0.1032, -0.0135],\n",
      "        [ 0.0806, -0.4255, -0.3987,  0.3057, -0.1336,  0.2743,  0.0320,  0.1829,\n",
      "          0.1233,  0.2041,  0.2788, -0.5192,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1184,  0.3457, -0.3251, -0.4996,  0.3800, -0.0859,  0.3155,  0.1557,\n",
      "         -0.4256,  0.1096,  0.1381, -0.3569, -0.2667,  0.1908,  0.1107, -0.2366]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2434,  0.2881, -0.1370,  0.5598,  0.4818, -0.0235, -0.3744,  0.3692,\n",
      "          0.1790, -0.3597,  0.3616,  0.3202,  0.4984, -0.3141, -0.1034, -0.0135],\n",
      "        [ 0.0806, -0.4255, -0.3987,  0.3057, -0.1336,  0.2743,  0.0320,  0.1829,\n",
      "          0.1233,  0.2041,  0.2788, -0.5192,  0.2829, -0.3952, -0.4234,  0.0343],\n",
      "        [-0.1188,  0.3459, -0.3251, -0.4996,  0.3795, -0.0860,  0.3154,  0.1553,\n",
      "         -0.4257,  0.1095,  0.1382, -0.3566, -0.2667,  0.1907,  0.1109, -0.2365]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2431,  0.2878, -0.1370,  0.5598,  0.4823, -0.0235, -0.3744,  0.3696,\n",
      "          0.1791, -0.3596,  0.3615,  0.3199,  0.4984, -0.3141, -0.1035, -0.0136],\n",
      "        [ 0.0806, -0.4255, -0.3987,  0.3057, -0.1337,  0.2743,  0.0320,  0.1829,\n",
      "          0.1233,  0.2041,  0.2788, -0.5192,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1192,  0.3462, -0.3251, -0.4996,  0.3790, -0.0860,  0.3154,  0.1549,\n",
      "         -0.4258,  0.1095,  0.1382, -0.3563, -0.2667,  0.1907,  0.1110, -0.2365]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2427,  0.2875, -0.1370,  0.5598,  0.4828, -0.0234, -0.3744,  0.3700,\n",
      "          0.1791, -0.3595,  0.3615,  0.3196,  0.4984, -0.3140, -0.1037, -0.0136],\n",
      "        [ 0.0806, -0.4254, -0.3987,  0.3057, -0.1337,  0.2743,  0.0320,  0.1829,\n",
      "          0.1233,  0.2041,  0.2788, -0.5191,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1195,  0.3464, -0.3251, -0.4996,  0.3785, -0.0861,  0.3154,  0.1545,\n",
      "         -0.4259,  0.1094,  0.1383, -0.3559, -0.2667,  0.1907,  0.1112, -0.2365]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2423,  0.2872, -0.1370,  0.5598,  0.4833, -0.0234, -0.3744,  0.3705,\n",
      "          0.1792, -0.3595,  0.3614,  0.3192,  0.4984, -0.3140, -0.1039, -0.0137],\n",
      "        [ 0.0806, -0.4254, -0.3987,  0.3057, -0.1337,  0.2743,  0.0320,  0.1828,\n",
      "          0.1233,  0.2041,  0.2788, -0.5191,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1199,  0.3467, -0.3251, -0.4996,  0.3780, -0.0861,  0.3154,  0.1541,\n",
      "         -0.4259,  0.1094,  0.1383, -0.3556, -0.2667,  0.1907,  0.1114, -0.2364]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2419,  0.2870, -0.1370,  0.5598,  0.4838, -0.0233, -0.3744,  0.3709,\n",
      "          0.1793, -0.3594,  0.3614,  0.3189,  0.4984, -0.3140, -0.1041, -0.0137],\n",
      "        [ 0.0805, -0.4254, -0.3987,  0.3057, -0.1338,  0.2743,  0.0320,  0.1828,\n",
      "          0.1233,  0.2041,  0.2788, -0.5191,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1203,  0.3469, -0.3251, -0.4996,  0.3776, -0.0861,  0.3154,  0.1537,\n",
      "         -0.4260,  0.1093,  0.1384, -0.3553, -0.2667,  0.1907,  0.1115, -0.2364]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2415,  0.2867, -0.1370,  0.5598,  0.4843, -0.0233, -0.3744,  0.3713,\n",
      "          0.1794, -0.3594,  0.3613,  0.3186,  0.4984, -0.3140, -0.1042, -0.0137],\n",
      "        [ 0.0805, -0.4254, -0.3987,  0.3057, -0.1338,  0.2743,  0.0320,  0.1828,\n",
      "          0.1233,  0.2041,  0.2788, -0.5191,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1206,  0.3472, -0.3250, -0.4996,  0.3771, -0.0862,  0.3154,  0.1533,\n",
      "         -0.4261,  0.1092,  0.1384, -0.3550, -0.2667,  0.1907,  0.1117, -0.2363]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2411,  0.2864, -0.1370,  0.5598,  0.4848, -0.0232, -0.3744,  0.3718,\n",
      "          0.1794, -0.3593,  0.3613,  0.3182,  0.4984, -0.3140, -0.1044, -0.0138],\n",
      "        [ 0.0805, -0.4254, -0.3987,  0.3057, -0.1338,  0.2743,  0.0320,  0.1828,\n",
      "          0.1233,  0.2041,  0.2788, -0.5191,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1210,  0.3475, -0.3250, -0.4996,  0.3766, -0.0862,  0.3154,  0.1529,\n",
      "         -0.4261,  0.1092,  0.1385, -0.3547, -0.2667,  0.1907,  0.1119, -0.2363]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2407,  0.2862, -0.1370,  0.5598,  0.4853, -0.0232, -0.3743,  0.3722,\n",
      "          0.1795, -0.3593,  0.3612,  0.3179,  0.4984, -0.3140, -0.1046, -0.0138],\n",
      "        [ 0.0805, -0.4254, -0.3987,  0.3057, -0.1338,  0.2743,  0.0320,  0.1827,\n",
      "          0.1233,  0.2041,  0.2788, -0.5190,  0.2829, -0.3952, -0.4233,  0.0343],\n",
      "        [-0.1214,  0.3477, -0.3250, -0.4996,  0.3761, -0.0863,  0.3154,  0.1524,\n",
      "         -0.4262,  0.1091,  0.1385, -0.3544, -0.2667,  0.1906,  0.1120, -0.2363]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2403,  0.2859, -0.1370,  0.5598,  0.4859, -0.0231, -0.3743,  0.3726,\n",
      "          0.1796, -0.3592,  0.3612,  0.3175,  0.4984, -0.3140, -0.1048, -0.0139],\n",
      "        [ 0.0804, -0.4253, -0.3987,  0.3057, -0.1339,  0.2743,  0.0320,  0.1827,\n",
      "          0.1233,  0.2041,  0.2788, -0.5190,  0.2829, -0.3952, -0.4233,  0.0344],\n",
      "        [-0.1218,  0.3480, -0.3250, -0.4996,  0.3757, -0.0863,  0.3154,  0.1520,\n",
      "         -0.4263,  0.1091,  0.1386, -0.3540, -0.2667,  0.1906,  0.1122, -0.2362]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2399,  0.2856, -0.1371,  0.5598,  0.4864, -0.0231, -0.3743,  0.3731,\n",
      "          0.1797, -0.3591,  0.3611,  0.3172,  0.4984, -0.3139, -0.1049, -0.0139],\n",
      "        [ 0.0804, -0.4253, -0.3987,  0.3057, -0.1339,  0.2743,  0.0320,  0.1827,\n",
      "          0.1233,  0.2041,  0.2788, -0.5190,  0.2829, -0.3952, -0.4233,  0.0344],\n",
      "        [-0.1221,  0.3482, -0.3250, -0.4996,  0.3752, -0.0864,  0.3153,  0.1516,\n",
      "         -0.4263,  0.1090,  0.1387, -0.3537, -0.2667,  0.1906,  0.1124, -0.2362]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2395,  0.2853, -0.1371,  0.5598,  0.4869, -0.0230, -0.3743,  0.3735,\n",
      "          0.1797, -0.3591,  0.3611,  0.3169,  0.4984, -0.3139, -0.1051, -0.0140],\n",
      "        [ 0.0804, -0.4253, -0.3987,  0.3057, -0.1339,  0.2743,  0.0320,  0.1827,\n",
      "          0.1233,  0.2041,  0.2788, -0.5190,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1225,  0.3485, -0.3250, -0.4996,  0.3747, -0.0864,  0.3153,  0.1512,\n",
      "         -0.4264,  0.1090,  0.1387, -0.3534, -0.2667,  0.1906,  0.1125, -0.2361]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2391,  0.2851, -0.1371,  0.5598,  0.4874, -0.0230, -0.3743,  0.3739,\n",
      "          0.1798, -0.3590,  0.3610,  0.3165,  0.4984, -0.3139, -0.1053, -0.0140],\n",
      "        [ 0.0804, -0.4253, -0.3987,  0.3057, -0.1340,  0.2743,  0.0320,  0.1826,\n",
      "          0.1232,  0.2041,  0.2788, -0.5190,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1229,  0.3487, -0.3250, -0.4996,  0.3742, -0.0864,  0.3153,  0.1508,\n",
      "         -0.4265,  0.1089,  0.1388, -0.3531, -0.2667,  0.1906,  0.1127, -0.2361]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2387,  0.2848, -0.1371,  0.5598,  0.4879, -0.0230, -0.3743,  0.3744,\n",
      "          0.1799, -0.3590,  0.3609,  0.3162,  0.4984, -0.3139, -0.1055, -0.0140],\n",
      "        [ 0.0803, -0.4253, -0.3987,  0.3057, -0.1340,  0.2743,  0.0320,  0.1826,\n",
      "          0.1232,  0.2041,  0.2788, -0.5189,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1232,  0.3490, -0.3250, -0.4996,  0.3738, -0.0865,  0.3153,  0.1504,\n",
      "         -0.4265,  0.1089,  0.1388, -0.3528, -0.2667,  0.1906,  0.1128, -0.2361]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2383,  0.2845, -0.1371,  0.5598,  0.4884, -0.0229, -0.3743,  0.3748,\n",
      "          0.1800, -0.3589,  0.3609,  0.3159,  0.4984, -0.3139, -0.1056, -0.0141],\n",
      "        [ 0.0803, -0.4253, -0.3987,  0.3057, -0.1340,  0.2743,  0.0320,  0.1826,\n",
      "          0.1232,  0.2041,  0.2788, -0.5189,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1236,  0.3492, -0.3250, -0.4996,  0.3733, -0.0865,  0.3153,  0.1500,\n",
      "         -0.4266,  0.1088,  0.1389, -0.3525, -0.2667,  0.1906,  0.1130, -0.2360]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2379,  0.2843, -0.1371,  0.5598,  0.4889, -0.0229, -0.3743,  0.3752,\n",
      "          0.1800, -0.3589,  0.3608,  0.3155,  0.4984, -0.3139, -0.1058, -0.0141],\n",
      "        [ 0.0803, -0.4252, -0.3987,  0.3057, -0.1341,  0.2743,  0.0320,  0.1826,\n",
      "          0.1232,  0.2041,  0.2788, -0.5189,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1240,  0.3495, -0.3250, -0.4996,  0.3728, -0.0866,  0.3153,  0.1496,\n",
      "         -0.4267,  0.1088,  0.1389, -0.3521, -0.2667,  0.1905,  0.1132, -0.2360]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2375,  0.2840, -0.1371,  0.5598,  0.4894, -0.0228, -0.3743,  0.3757,\n",
      "          0.1801, -0.3588,  0.3608,  0.3152,  0.4984, -0.3139, -0.1060, -0.0142],\n",
      "        [ 0.0803, -0.4252, -0.3987,  0.3057, -0.1341,  0.2743,  0.0320,  0.1825,\n",
      "          0.1232,  0.2041,  0.2788, -0.5189,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1244,  0.3498, -0.3250, -0.4996,  0.3723, -0.0866,  0.3153,  0.1492,\n",
      "         -0.4268,  0.1087,  0.1390, -0.3518, -0.2667,  0.1905,  0.1133, -0.2359]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2371,  0.2837, -0.1371,  0.5598,  0.4899, -0.0228, -0.3742,  0.3761,\n",
      "          0.1802, -0.3587,  0.3607,  0.3148,  0.4984, -0.3138, -0.1062, -0.0142],\n",
      "        [ 0.0803, -0.4252, -0.3987,  0.3057, -0.1341,  0.2743,  0.0320,  0.1825,\n",
      "          0.1232,  0.2041,  0.2788, -0.5189,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1247,  0.3500, -0.3250, -0.4996,  0.3719, -0.0867,  0.3153,  0.1488,\n",
      "         -0.4268,  0.1086,  0.1390, -0.3515, -0.2667,  0.1905,  0.1135, -0.2359]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2367,  0.2834, -0.1371,  0.5598,  0.4904, -0.0227, -0.3742,  0.3765,\n",
      "          0.1803, -0.3587,  0.3607,  0.3145,  0.4984, -0.3138, -0.1063, -0.0143],\n",
      "        [ 0.0802, -0.4252, -0.3987,  0.3057, -0.1341,  0.2743,  0.0320,  0.1825,\n",
      "          0.1232,  0.2041,  0.2788, -0.5188,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1251,  0.3503, -0.3250, -0.4996,  0.3714, -0.0867,  0.3153,  0.1484,\n",
      "         -0.4269,  0.1086,  0.1391, -0.3512, -0.2667,  0.1905,  0.1137, -0.2359]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2363,  0.2832, -0.1371,  0.5598,  0.4909, -0.0227, -0.3742,  0.3770,\n",
      "          0.1803, -0.3586,  0.3606,  0.3142,  0.4984, -0.3138, -0.1065, -0.0143],\n",
      "        [ 0.0802, -0.4252, -0.3987,  0.3057, -0.1342,  0.2743,  0.0320,  0.1825,\n",
      "          0.1232,  0.2040,  0.2788, -0.5188,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1255,  0.3505, -0.3250, -0.4996,  0.3709, -0.0867,  0.3153,  0.1479,\n",
      "         -0.4270,  0.1085,  0.1391, -0.3509, -0.2667,  0.1905,  0.1138, -0.2358]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2359,  0.2829, -0.1371,  0.5598,  0.4914, -0.0226, -0.3742,  0.3774,\n",
      "          0.1804, -0.3586,  0.3606,  0.3138,  0.4984, -0.3138, -0.1067, -0.0143],\n",
      "        [ 0.0802, -0.4252, -0.3987,  0.3057, -0.1342,  0.2743,  0.0320,  0.1824,\n",
      "          0.1232,  0.2040,  0.2788, -0.5188,  0.2829, -0.3952, -0.4232,  0.0344],\n",
      "        [-0.1258,  0.3508, -0.3250, -0.4996,  0.3704, -0.0868,  0.3152,  0.1475,\n",
      "         -0.4270,  0.1085,  0.1392, -0.3506, -0.2667,  0.1905,  0.1140, -0.2358]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2355,  0.2826, -0.1371,  0.5598,  0.4919, -0.0226, -0.3742,  0.3778,\n",
      "          0.1805, -0.3585,  0.3605,  0.3135,  0.4984, -0.3138, -0.1069, -0.0144],\n",
      "        [ 0.0802, -0.4252, -0.3987,  0.3057, -0.1342,  0.2743,  0.0320,  0.1824,\n",
      "          0.1232,  0.2040,  0.2788, -0.5188,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1262,  0.3510, -0.3250, -0.4996,  0.3700, -0.0868,  0.3152,  0.1471,\n",
      "         -0.4271,  0.1084,  0.1392, -0.3502, -0.2667,  0.1905,  0.1142, -0.2357]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2352,  0.2823, -0.1371,  0.5598,  0.4924, -0.0226, -0.3742,  0.3783,\n",
      "          0.1806, -0.3584,  0.3604,  0.3132,  0.4984, -0.3138, -0.1070, -0.0144],\n",
      "        [ 0.0801, -0.4251, -0.3987,  0.3057, -0.1343,  0.2743,  0.0320,  0.1824,\n",
      "          0.1232,  0.2040,  0.2788, -0.5188,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1266,  0.3513, -0.3249, -0.4996,  0.3695, -0.0869,  0.3152,  0.1467,\n",
      "         -0.4272,  0.1084,  0.1393, -0.3499, -0.2667,  0.1904,  0.1143, -0.2357]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2348,  0.2821, -0.1371,  0.5598,  0.4929, -0.0225, -0.3742,  0.3787,\n",
      "          0.1806, -0.3584,  0.3604,  0.3128,  0.4984, -0.3137, -0.1072, -0.0145],\n",
      "        [ 0.0801, -0.4251, -0.3987,  0.3057, -0.1343,  0.2743,  0.0320,  0.1823,\n",
      "          0.1232,  0.2040,  0.2788, -0.5187,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1270,  0.3515, -0.3249, -0.4996,  0.3690, -0.0869,  0.3152,  0.1463,\n",
      "         -0.4272,  0.1083,  0.1393, -0.3496, -0.2667,  0.1904,  0.1145, -0.2357]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2344,  0.2818, -0.1371,  0.5598,  0.4934, -0.0225, -0.3742,  0.3792,\n",
      "          0.1807, -0.3583,  0.3603,  0.3125,  0.4984, -0.3137, -0.1074, -0.0145],\n",
      "        [ 0.0801, -0.4251, -0.3987,  0.3057, -0.1343,  0.2743,  0.0320,  0.1823,\n",
      "          0.1232,  0.2040,  0.2788, -0.5187,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1273,  0.3518, -0.3249, -0.4996,  0.3685, -0.0870,  0.3152,  0.1459,\n",
      "         -0.4273,  0.1083,  0.1394, -0.3493, -0.2667,  0.1904,  0.1147, -0.2356]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2340,  0.2815, -0.1371,  0.5598,  0.4939, -0.0224, -0.3742,  0.3796,\n",
      "          0.1808, -0.3583,  0.3603,  0.3121,  0.4984, -0.3137, -0.1076, -0.0146],\n",
      "        [ 0.0801, -0.4251, -0.3987,  0.3057, -0.1344,  0.2743,  0.0320,  0.1823,\n",
      "          0.1232,  0.2040,  0.2788, -0.5187,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1277,  0.3521, -0.3249, -0.4996,  0.3681, -0.0870,  0.3152,  0.1455,\n",
      "         -0.4274,  0.1082,  0.1394, -0.3490, -0.2667,  0.1904,  0.1148, -0.2356]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2336,  0.2813, -0.1372,  0.5598,  0.4944, -0.0224, -0.3742,  0.3800,\n",
      "          0.1809, -0.3582,  0.3602,  0.3118,  0.4984, -0.3137, -0.1077, -0.0146],\n",
      "        [ 0.0800, -0.4251, -0.3987,  0.3057, -0.1344,  0.2743,  0.0320,  0.1823,\n",
      "          0.1232,  0.2040,  0.2788, -0.5187,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1281,  0.3523, -0.3249, -0.4996,  0.3676, -0.0870,  0.3152,  0.1451,\n",
      "         -0.4275,  0.1082,  0.1395, -0.3486, -0.2667,  0.1904,  0.1150, -0.2355]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2332,  0.2810, -0.1372,  0.5598,  0.4950, -0.0223, -0.3741,  0.3805,\n",
      "          0.1809, -0.3582,  0.3602,  0.3115,  0.4984, -0.3137, -0.1079, -0.0146],\n",
      "        [ 0.0800, -0.4251, -0.3987,  0.3057, -0.1344,  0.2743,  0.0320,  0.1822,\n",
      "          0.1232,  0.2040,  0.2789, -0.5187,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1284,  0.3526, -0.3249, -0.4996,  0.3671, -0.0871,  0.3152,  0.1447,\n",
      "         -0.4275,  0.1081,  0.1395, -0.3483, -0.2667,  0.1904,  0.1152, -0.2355]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2328,  0.2807, -0.1372,  0.5598,  0.4955, -0.0223, -0.3741,  0.3809,\n",
      "          0.1810, -0.3581,  0.3601,  0.3111,  0.4984, -0.3137, -0.1081, -0.0147],\n",
      "        [ 0.0800, -0.4250, -0.3987,  0.3057, -0.1344,  0.2743,  0.0320,  0.1822,\n",
      "          0.1232,  0.2040,  0.2789, -0.5186,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1288,  0.3528, -0.3249, -0.4996,  0.3666, -0.0871,  0.3152,  0.1443,\n",
      "         -0.4276,  0.1080,  0.1396, -0.3480, -0.2667,  0.1904,  0.1153, -0.2355]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2324,  0.2804, -0.1372,  0.5598,  0.4960, -0.0222, -0.3741,  0.3813,\n",
      "          0.1811, -0.3580,  0.3601,  0.3108,  0.4984, -0.3137, -0.1083, -0.0147],\n",
      "        [ 0.0800, -0.4250, -0.3987,  0.3057, -0.1345,  0.2743,  0.0320,  0.1822,\n",
      "          0.1232,  0.2040,  0.2789, -0.5186,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1292,  0.3531, -0.3249, -0.4996,  0.3662, -0.0872,  0.3152,  0.1439,\n",
      "         -0.4277,  0.1080,  0.1396, -0.3477, -0.2667,  0.1903,  0.1155, -0.2354]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2320,  0.2802, -0.1372,  0.5598,  0.4965, -0.0222, -0.3741,  0.3818,\n",
      "          0.1811, -0.3580,  0.3600,  0.3105,  0.4984, -0.3136, -0.1084, -0.0148],\n",
      "        [ 0.0799, -0.4250, -0.3987,  0.3057, -0.1345,  0.2743,  0.0320,  0.1822,\n",
      "          0.1232,  0.2040,  0.2789, -0.5186,  0.2829, -0.3952, -0.4231,  0.0344],\n",
      "        [-0.1296,  0.3533, -0.3249, -0.4996,  0.3657, -0.0872,  0.3151,  0.1434,\n",
      "         -0.4277,  0.1079,  0.1397, -0.3474, -0.2667,  0.1903,  0.1156, -0.2354]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2316,  0.2799, -0.1372,  0.5598,  0.4970, -0.0221, -0.3741,  0.3822,\n",
      "          0.1812, -0.3579,  0.3600,  0.3101,  0.4984, -0.3136, -0.1086, -0.0148],\n",
      "        [ 0.0799, -0.4250, -0.3987,  0.3057, -0.1345,  0.2743,  0.0320,  0.1821,\n",
      "          0.1232,  0.2040,  0.2789, -0.5186,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1299,  0.3536, -0.3249, -0.4996,  0.3652, -0.0872,  0.3151,  0.1430,\n",
      "         -0.4278,  0.1079,  0.1397, -0.3471, -0.2667,  0.1903,  0.1158, -0.2353]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2312,  0.2796, -0.1372,  0.5598,  0.4975, -0.0221, -0.3741,  0.3826,\n",
      "          0.1813, -0.3579,  0.3599,  0.3098,  0.4984, -0.3136, -0.1088, -0.0149],\n",
      "        [ 0.0799, -0.4250, -0.3987,  0.3057, -0.1346,  0.2742,  0.0320,  0.1821,\n",
      "          0.1232,  0.2040,  0.2789, -0.5186,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1303,  0.3539, -0.3249, -0.4996,  0.3647, -0.0873,  0.3151,  0.1426,\n",
      "         -0.4279,  0.1078,  0.1398, -0.3467, -0.2667,  0.1903,  0.1160, -0.2353]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2308,  0.2794, -0.1372,  0.5598,  0.4980, -0.0221, -0.3741,  0.3831,\n",
      "          0.1814, -0.3578,  0.3598,  0.3094,  0.4984, -0.3136, -0.1090, -0.0149],\n",
      "        [ 0.0799, -0.4250, -0.3987,  0.3057, -0.1346,  0.2742,  0.0320,  0.1821,\n",
      "          0.1232,  0.2040,  0.2789, -0.5185,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1307,  0.3541, -0.3249, -0.4996,  0.3643, -0.0873,  0.3151,  0.1422,\n",
      "         -0.4279,  0.1078,  0.1398, -0.3464, -0.2667,  0.1903,  0.1161, -0.2353]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2304,  0.2791, -0.1372,  0.5598,  0.4985, -0.0220, -0.3741,  0.3835,\n",
      "          0.1814, -0.3577,  0.3598,  0.3091,  0.4984, -0.3136, -0.1091, -0.0149],\n",
      "        [ 0.0799, -0.4249, -0.3987,  0.3057, -0.1346,  0.2742,  0.0320,  0.1821,\n",
      "          0.1231,  0.2040,  0.2789, -0.5185,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1310,  0.3544, -0.3249, -0.4996,  0.3638, -0.0874,  0.3151,  0.1418,\n",
      "         -0.4280,  0.1077,  0.1399, -0.3461, -0.2667,  0.1903,  0.1163, -0.2352]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2300,  0.2788, -0.1372,  0.5598,  0.4990, -0.0220, -0.3741,  0.3839,\n",
      "          0.1815, -0.3577,  0.3597,  0.3088,  0.4984, -0.3136, -0.1093, -0.0150],\n",
      "        [ 0.0798, -0.4249, -0.3987,  0.3057, -0.1347,  0.2742,  0.0320,  0.1820,\n",
      "          0.1231,  0.2040,  0.2789, -0.5185,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1314,  0.3546, -0.3249, -0.4996,  0.3633, -0.0874,  0.3151,  0.1414,\n",
      "         -0.4281,  0.1077,  0.1399, -0.3458, -0.2667,  0.1903,  0.1165, -0.2352]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2296,  0.2785, -0.1372,  0.5598,  0.4995, -0.0219, -0.3740,  0.3844,\n",
      "          0.1816, -0.3576,  0.3597,  0.3084,  0.4984, -0.3136, -0.1095, -0.0150],\n",
      "        [ 0.0798, -0.4249, -0.3987,  0.3057, -0.1347,  0.2742,  0.0320,  0.1820,\n",
      "          0.1231,  0.2040,  0.2789, -0.5185,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1318,  0.3549, -0.3249, -0.4996,  0.3628, -0.0875,  0.3151,  0.1410,\n",
      "         -0.4282,  0.1076,  0.1400, -0.3455, -0.2667,  0.1902,  0.1166, -0.2351]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2292,  0.2783, -0.1372,  0.5598,  0.5000, -0.0219, -0.3740,  0.3848,\n",
      "          0.1817, -0.3576,  0.3596,  0.3081,  0.4984, -0.3135, -0.1097, -0.0151],\n",
      "        [ 0.0798, -0.4249, -0.3987,  0.3057, -0.1347,  0.2742,  0.0320,  0.1820,\n",
      "          0.1231,  0.2040,  0.2789, -0.5185,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1322,  0.3551, -0.3249, -0.4996,  0.3624, -0.0875,  0.3151,  0.1406,\n",
      "         -0.4282,  0.1076,  0.1400, -0.3452, -0.2667,  0.1902,  0.1168, -0.2351]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n",
      "================================================================================\n",
      "previous action tensor([1., 0., 0.], grad_fn=<SoftmaxBackward>)\n",
      "tensor([[-3.9487e-02,  2.7211e-02,  6.3814e-04, -8.4888e-05, -5.0570e-02,\n",
      "         -4.5319e-03, -1.0833e-03, -4.3468e-02, -7.4077e-03, -5.7967e-03,\n",
      "          5.4988e-03,  3.3739e-02, -4.7385e-05, -1.5014e-03,  1.7510e-02,\n",
      "          4.2734e-03],\n",
      "        [ 2.3423e-03, -1.6142e-03, -3.7862e-05,  5.0957e-06,  2.9998e-03,\n",
      "          2.6890e-04,  6.4237e-05,  2.5785e-03,  4.3946e-04,  3.4384e-04,\n",
      "         -3.2625e-04, -2.0015e-03,  2.8473e-06,  8.9037e-05, -1.0387e-03,\n",
      "         -2.5334e-04],\n",
      "        [ 3.7145e-02, -2.5597e-02, -6.0028e-04,  7.9792e-05,  4.7570e-02,\n",
      "          4.2630e-03,  1.0190e-03,  4.0890e-02,  6.9683e-03,  5.4528e-03,\n",
      "         -5.1725e-03, -3.1738e-02,  4.4537e-05,  1.4124e-03, -1.6472e-02,\n",
      "         -4.0201e-03]])\n",
      "******weights******\n",
      "tensor([[-0.2288,  0.2780, -0.1372,  0.5598,  0.5005, -0.0218, -0.3740,  0.3852,\n",
      "          0.1817, -0.3575,  0.3596,  0.3078,  0.4984, -0.3135, -0.1098, -0.0151],\n",
      "        [ 0.0798, -0.4249, -0.3987,  0.3057, -0.1347,  0.2742,  0.0320,  0.1820,\n",
      "          0.1231,  0.2040,  0.2789, -0.5184,  0.2829, -0.3952, -0.4230,  0.0344],\n",
      "        [-0.1325,  0.3554, -0.3249, -0.4996,  0.3619, -0.0875,  0.3151,  0.1402,\n",
      "         -0.4283,  0.1075,  0.1401, -0.3448, -0.2667,  0.1902,  0.1170, -0.2351]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2824.0\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "T = 3602\n",
    "m = 10\n",
    "to_draw = np.sort(Pad['timestamp'].unique())\n",
    "ccy = np.sort(Pad['currency pair'].unique())\n",
    "min_history = 500 # min episode length\n",
    "\n",
    "    \n",
    "def generate_episode(n,cur):\n",
    "    _max = to_draw.shape[0]\n",
    "    _end = min(n+T, _max)\n",
    "    timeframe = to_draw[n:_end]\n",
    "    other_bid = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    other_ask = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    i = 0\n",
    "    for elem in ccy:\n",
    "        tmp = Pad[Pad['currency pair'] == elem]\n",
    "        if elem == cur:\n",
    "            target_bid = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            target_ask = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "        else:\n",
    "            other_bid[:,i] = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            other_ask[:,i] = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "            i += 1\n",
    "    return target_bid, target_ask, other_bid, other_ask\n",
    "\n",
    "def features(price_path,m):\n",
    "    features = np.zeros((price_path.shape[0]-m,m))\n",
    "    for i in range(m):\n",
    "        features[:,i] = (np.log(price_path) - np.log(np.roll(price_path, i+1)))[m:]\n",
    "    return features\n",
    "\n",
    "def get_features(target_bid, target_ask, other_bid, other_ask, m):\n",
    "    feature_span = features(target_bid,m)\n",
    "    feature_span = np.append(feature_span, features(target_ask,m), axis = 1)\n",
    "    for i in range(other_bid.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_bid[:,i],m), axis = 1)\n",
    "    for j in range(other_ask.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_ask[:,j],m), axis = 1)\n",
    "    return feature_span\n",
    "\n",
    "def draw_episode(m, cur, min_history):\n",
    "    '''\n",
    "    Input:\n",
    "        m, number of lag returns z_1,...z_m\n",
    "        cur, currency pair that we target to trade\n",
    "        min_history, min length of a valid episode\n",
    "    '''\n",
    "#     n = np.random.randint(to_draw.shape[0] - min_history)\n",
    "    n = 8000\n",
    "    target_bid, target_ask, other_bid, other_ask = generate_episode(n,cur)\n",
    "    feature_span = get_features(target_bid, target_ask, other_bid, other_ask, m)\n",
    "    normalized = (feature_span-feature_span.mean(axis=1))/feature_span.std(axis=1)\n",
    "    return target_bid, target_ask, normalized\n",
    "import gym\n",
    "import gym_banana\n",
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "# parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "#                     help='discount factor (default: 0.99)')\n",
    "# parser.add_argument('--seed', type=int, default=543, metavar='N',\n",
    "#                     help='random seed (default: 543)')\n",
    "# parser.add_argument('--render', action='store_true',\n",
    "#                     help='render the environment')\n",
    "# parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "#                     help='interval between training status logs (default: 10)')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n",
    "env = gym.make('Banana-v0')\n",
    "env.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(16, 3, bias = True)\n",
    "#         self.A = Variable(torch.randn(256, 3), requires_grad=True)\n",
    "#         self.b = Variable(torch.randn(1), requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform(self.affine1.weight)\n",
    "        #print('The weight of the affine layer is', self.affine1.weight)\n",
    "#         self.dropout = nn.Dropout(p=0)\n",
    "#        self.mu = Variable(torch.randn(3, 3), requires_grad=True)\n",
    "        #self.mu = nn.Linear(1,3, bias = True)\n",
    "                #torch.nn.init.xavier_uniform(self.affine1.weight)\n",
    "        #print('The weight of the affine layer is', self.affine1.weight)\n",
    "        # self.tanh = nn.Tanh()\n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = 0\n",
    "        self.actions = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.affine1(x)\n",
    "#         x = torch.matmul(x, self.A) \n",
    "#         x = self.dropout(x)\n",
    "#         print(x.size())\n",
    "        #mu_sigma = torch.matmul(y, self.mu)\n",
    "#         print(mu_sigma.size())\n",
    "        # action = self.tanh(x + mu_sigma)\n",
    "        # action = self.softmax(action)\n",
    "        action = self.softmax(x)\n",
    "#         action_scores = self.affine2(x)\n",
    "#         return F.softmax(action_scores, dim=1)\n",
    "        return action\n",
    "\n",
    "\n",
    "global policy\n",
    "policy = Policy()\n",
    "\n",
    "optimizer = optim.SGD(policy.parameters(), lr=1e-2)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "\n",
    "# def select_action(state, previous_action):\n",
    "#     state = torch.from_numpy(state).float()\n",
    "#     previous_action = previous_action\n",
    "#     probs = policy(state, previous_action)\n",
    "    #return probs\n",
    "    #m = Categorical(probs)\n",
    "    #action = m.sample()\n",
    "    #policy.saved_log_probs.append(m.log_prob(action))\n",
    "#     return probs.detach().numpy()\n",
    "    #return action.item() - 1\n",
    "\n",
    "\n",
    "def finish_episode(num):\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    returns = []\n",
    "#     for r in policy.rewards[::-1]:\n",
    "#         #print(\"reward\",r * 1000000)\n",
    "# #         R = r\n",
    "#         returns.insert(0, R)\n",
    "#     returns = torch.tensor(returns)\n",
    "#     optimizer.zero_grad()\n",
    "#     # returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "#     for R in returns:\n",
    "# #         print(Variable(-torch.ones(log_prob.shape), requires_grad = True) * R)\n",
    "#         #print(\"return\", R)\n",
    "#         #print(\"policy_append\", Variable(-torch.ones(log_prob.shape) * 1000000, requires_grad = True) * R)\n",
    "#         #policy_loss.append( torch.tensor(-1000000* R))\n",
    "#         policy_loss.append(Variable(-torch.ones((1,)) * 1000000, requires_grad = True) * R)\n",
    " \n",
    "#     policy_loss = torch.cat(policy_loss).sum() \n",
    "#     #policy_loss = policy.A.sum()\n",
    "#     policy_loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(policy.A.grad)\n",
    "#     #print(policy.b.grad)\n",
    "#     #print(list(policy.parameters()))\n",
    "#     print (\"Finished {} episode and the policy loss is {}\".format(num, policy_loss))\n",
    "#     policy.rewards = []\n",
    "    #optimizer.zero_grad()\n",
    "    #del policy.saved|_log_probs[:]\n",
    "    print(policy.A.grad)\n",
    "    print(policy.b.grad)\n",
    "    loss = policy.A.sum()\n",
    "    loss.backward()\n",
    "    policy.rewards.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    mask = torch.tensor([-1, 0, 1]).float()\n",
    "    for i_episode in range(100):\n",
    "        ask = np.zeros((1, 1))\n",
    "        bid = np.zeros((1,1 ))\n",
    "        previous_action = np.array([0, 0, 1])\n",
    "        while ask.shape[0] <= 3600 and bid.shape[0]<=3600:\n",
    "            target_bid, target_ask, feature_span = draw_episode(1, 'AUDUSD', 1000)\n",
    "            bid, ask, features = target_bid[1:]*1e5, target_ask[1:]*1e5, feature_span\n",
    "        for t in range(3600):  # Don't infinite loop while learning\n",
    "            state = feature_span[t]\n",
    "#             action = select_action(state, previous_action)\n",
    "            action = policy(torch.from_numpy(state).float())\n",
    "            after_mask = action * mask\n",
    "#             print('The action chosen at the current step is {}'.format(after_mask))\n",
    "#             action = Variable(action, requires_grad=True)\n",
    "#             reward = ((action) * (ask[t+1] - ask[t]) + (bid[t+1] - bid[t]))\n",
    "#             reward = Variable(torch.tensor([reward.sum()]), requires_grad=True)\n",
    "            price_change = (ask[t+1] - ask[t]) + (bid[t+1] - bid[t])\n",
    "#             print ('The price change is {}'.format(price_change))\n",
    "#             print('A preview of price change {}'.format(after_mask * price_change))\n",
    "            reward = torch.sum(after_mask * price_change)\n",
    "#             print('what we can get {}'.format(reward.float().item()))\n",
    "#             print('The price chance at this time step is {}'.format(price_change))\n",
    "            \n",
    "            policy.rewards += reward\n",
    "#             print('The cumulative reward so far is {}'.format(policy.rewards))\n",
    "#             ep_reward += reward\n",
    "            #policy.actions.append(action)\n",
    "            previous_action = action\n",
    "\n",
    "\n",
    "        \n",
    "#         running_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward\n",
    "#         finish_episode(i_episode)\n",
    "#         print(policy.A.grad)\n",
    "#         print(policy.b.grad)\n",
    "        print(80*'=')\n",
    "        print ('previous action {}'.format(previous_action))\n",
    "        if policy.affine1.weight.grad is not None:\n",
    "            print(policy.affine1.weight.grad)\n",
    "            print('******weights******')\n",
    "            print(policy.affine1.weight.data)\n",
    "#         policy.rewards.backward()\n",
    "#         loss = policy.A.sum()\n",
    "        \n",
    "        loss = - policy.rewards\n",
    "        print (type(loss))\n",
    "        print(loss.size())\n",
    "        print(type(policy.rewards))\n",
    "        print(torch.sum(policy.rewards).size())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print('The loss of training is {}'.format(loss.item()))\n",
    "        policy.rewards = 0\n",
    "#         optimizer.zero_grad()\n",
    "#         if i_episode % 5 == 0:\n",
    "#             print('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format(\n",
    "#                   i_episode, ep_reward, running_reward))\n",
    "#         if running_reward > env.spec.reward_threshold:\n",
    "#             print(\"Solved! Running reward is now {} and \"\n",
    "#                   \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "#             break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-04-28 00:41:34,673 - root - INFO - BananaEnv - Version 0.1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yilun/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:93: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "previous action tensor([-0.0230], grad_fn=<TanhBackward>)\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 6.741825200151652e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0221], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2275e-04, -4.8325e-04,  8.6255e-05,  1.0477e-03,  8.8287e-05,\n",
      "          4.4157e-04, -1.7045e-04, -1.3647e-03, -3.4695e-04, -2.2551e-07,\n",
      "         -4.0916e-04,  2.7266e-04,  2.4595e-04,  7.9067e-06,  1.2086e-03,\n",
      "          5.4806e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0023,  0.5194,  0.1849, -0.2213, -0.3588, -0.0996, -0.2562, -0.1902,\n",
      "          0.0285,  0.3542,  0.3229, -0.5808,  0.3683,  0.1660,  0.5634,  0.3921]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 5.881975084776059e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0211], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2309e-04, -4.8353e-04,  8.6207e-05,  1.0478e-03,  8.8069e-05,\n",
      "          4.4163e-04, -1.7036e-04, -1.3648e-03, -3.4683e-04, -2.8953e-07,\n",
      "         -4.0922e-04,  2.7242e-04,  2.4605e-04,  7.9086e-06,  1.2088e-03,\n",
      "          5.4803e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0023,  0.5194,  0.1849, -0.2215, -0.3588, -0.0997, -0.2562, -0.1901,\n",
      "          0.0285,  0.3542,  0.3230, -0.5808,  0.3682,  0.1660,  0.5633,  0.3920]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 5.022085315431468e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0202], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2343e-04, -4.8381e-04,  8.6159e-05,  1.0479e-03,  8.7850e-05,\n",
      "          4.4169e-04, -1.7028e-04, -1.3650e-03, -3.4670e-04, -3.5371e-07,\n",
      "         -4.0928e-04,  2.7218e-04,  2.4615e-04,  7.9105e-06,  1.2089e-03,\n",
      "          5.4801e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0023,  0.5195,  0.1848, -0.2216, -0.3588, -0.0997, -0.2562, -0.1900,\n",
      "          0.0285,  0.3542,  0.3230, -0.5808,  0.3682,  0.1660,  0.5632,  0.3920]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 4.1621395212132484e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0193], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2377e-04, -4.8409e-04,  8.6110e-05,  1.0480e-03,  8.7632e-05,\n",
      "          4.4175e-04, -1.7020e-04, -1.3652e-03, -3.4657e-04, -4.1792e-07,\n",
      "         -4.0933e-04,  2.7193e-04,  2.4625e-04,  7.9124e-06,  1.2090e-03,\n",
      "          5.4798e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0022,  0.5195,  0.1848, -0.2217, -0.3588, -0.0998, -0.2562, -0.1898,\n",
      "          0.0286,  0.3542,  0.3231, -0.5809,  0.3682,  0.1660,  0.5630,  0.3919]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 3.302100594737567e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0184], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2411e-04, -4.8437e-04,  8.6062e-05,  1.0481e-03,  8.7413e-05,\n",
      "          4.4180e-04, -1.7011e-04, -1.3653e-03, -3.4644e-04, -4.8209e-07,\n",
      "         -4.0939e-04,  2.7169e-04,  2.4635e-04,  7.9144e-06,  1.2091e-03,\n",
      "          5.4795e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0022,  0.5196,  0.1848, -0.2218, -0.3589, -0.0998, -0.2562, -0.1897,\n",
      "          0.0286,  0.3542,  0.3231, -0.5809,  0.3682,  0.1660,  0.5629,  0.3919]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 2.441929427732248e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0175], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2446e-04, -4.8465e-04,  8.6013e-05,  1.0482e-03,  8.7194e-05,\n",
      "          4.4186e-04, -1.7003e-04, -1.3655e-03, -3.4631e-04, -5.4649e-07,\n",
      "         -4.0945e-04,  2.7145e-04,  2.4645e-04,  7.9165e-06,  1.2093e-03,\n",
      "          5.4793e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0022,  0.5196,  0.1848, -0.2219, -0.3589, -0.0998, -0.2562, -0.1896,\n",
      "          0.0287,  0.3542,  0.3232, -0.5809,  0.3681,  0.1660,  0.5628,  0.3918]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 1.581827746122144e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0166], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2480e-04, -4.8492e-04,  8.5964e-05,  1.0483e-03,  8.6975e-05,\n",
      "          4.4192e-04, -1.6994e-04, -1.3657e-03, -3.4618e-04, -6.1090e-07,\n",
      "         -4.0950e-04,  2.7121e-04,  2.4655e-04,  7.9185e-06,  1.2094e-03,\n",
      "          5.4790e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0021,  0.5197,  0.1848, -0.2220, -0.3589, -0.0999, -0.2561, -0.1894,\n",
      "          0.0287,  0.3542,  0.3232, -0.5809,  0.3681,  0.1660,  0.5627,  0.3918]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is 7.216334324766649e-06\n",
      "================================================================================\n",
      "previous action tensor([-0.0157], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2514e-04, -4.8520e-04,  8.5915e-05,  1.0484e-03,  8.6755e-05,\n",
      "          4.4198e-04, -1.6986e-04, -1.3658e-03, -3.4606e-04, -6.7540e-07,\n",
      "         -4.0956e-04,  2.7096e-04,  2.4665e-04,  7.9206e-06,  1.2095e-03,\n",
      "          5.4787e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0021,  0.5197,  0.1848, -0.2221, -0.3589, -0.0999, -0.2561, -0.1893,\n",
      "          0.0287,  0.3542,  0.3232, -0.5810,  0.3681,  0.1660,  0.5626,  0.3917]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -1.3870662769477349e-06\n",
      "================================================================================\n",
      "previous action tensor([-0.0148], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2548e-04, -4.8548e-04,  8.5866e-05,  1.0485e-03,  8.6535e-05,\n",
      "          4.4203e-04, -1.6977e-04, -1.3660e-03, -3.4593e-04, -7.3990e-07,\n",
      "         -4.0961e-04,  2.7072e-04,  2.4675e-04,  7.9226e-06,  1.2096e-03,\n",
      "          5.4784e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0021,  0.5198,  0.1848, -0.2222, -0.3589, -0.1000, -0.2561, -0.1891,\n",
      "          0.0288,  0.3542,  0.3233, -0.5810,  0.3681,  0.1660,  0.5624,  0.3916]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -9.990665603254456e-06\n",
      "================================================================================\n",
      "previous action tensor([-0.0139], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2582e-04, -4.8576e-04,  8.5816e-05,  1.0486e-03,  8.6315e-05,\n",
      "          4.4209e-04, -1.6969e-04, -1.3661e-03, -3.4579e-04, -8.0466e-07,\n",
      "         -4.0967e-04,  2.7048e-04,  2.4685e-04,  7.9248e-06,  1.2097e-03,\n",
      "          5.4781e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0020,  0.5198,  0.1848, -0.2223, -0.3589, -0.1000, -0.2561, -0.1890,\n",
      "          0.0288,  0.3542,  0.3233, -0.5810,  0.3680,  0.1660,  0.5623,  0.3916]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -1.8593800632515922e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0130], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2616e-04, -4.8604e-04,  8.5766e-05,  1.0486e-03,  8.6094e-05,\n",
      "          4.4214e-04, -1.6960e-04, -1.3663e-03, -3.4566e-04, -8.6946e-07,\n",
      "         -4.0972e-04,  2.7023e-04,  2.4694e-04,  7.9269e-06,  1.2098e-03,\n",
      "          5.4778e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0020,  0.5199,  0.1848, -0.2224, -0.3589, -0.1001, -0.2561, -0.1889,\n",
      "          0.0288,  0.3542,  0.3234, -0.5811,  0.3680,  0.1660,  0.5622,  0.3915]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -2.71978642558679e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0121], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2650e-04, -4.8631e-04,  8.5717e-05,  1.0487e-03,  8.5873e-05,\n",
      "          4.4220e-04, -1.6951e-04, -1.3664e-03, -3.4553e-04, -9.3430e-07,\n",
      "         -4.0977e-04,  2.6999e-04,  2.4704e-04,  7.9291e-06,  1.2099e-03,\n",
      "          5.4775e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0020,  0.5199,  0.1848, -0.2225, -0.3589, -0.1001, -0.2561, -0.1887,\n",
      "          0.0289,  0.3542,  0.3234, -0.5811,  0.3680,  0.1660,  0.5621,  0.3915]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -3.58019933628384e-05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "previous action tensor([-0.0112], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2684e-04, -4.8659e-04,  8.5667e-05,  1.0488e-03,  8.5652e-05,\n",
      "          4.4225e-04, -1.6943e-04, -1.3666e-03, -3.4540e-04, -9.9918e-07,\n",
      "         -4.0983e-04,  2.6974e-04,  2.4714e-04,  7.9313e-06,  1.2101e-03,\n",
      "          5.4772e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0020,  0.5200,  0.1848, -0.2226, -0.3589, -0.1002, -0.2560, -0.1886,\n",
      "          0.0289,  0.3542,  0.3234, -0.5811,  0.3680,  0.1660,  0.5620,  0.3914]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -4.440671909833327e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0103], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2718e-04, -4.8687e-04,  8.5616e-05,  1.0489e-03,  8.5430e-05,\n",
      "          4.4231e-04, -1.6934e-04, -1.3667e-03, -3.4527e-04, -1.0642e-06,\n",
      "         -4.0988e-04,  2.6949e-04,  2.4724e-04,  7.9335e-06,  1.2102e-03,\n",
      "          5.4768e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0019,  0.5200,  0.1848, -0.2227, -0.3589, -0.1002, -0.2560, -0.1885,\n",
      "          0.0289,  0.3542,  0.3235, -0.5811,  0.3679,  0.1660,  0.5618,  0.3914]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -5.301220517139882e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0094], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2752e-04, -4.8715e-04,  8.5566e-05,  1.0489e-03,  8.5209e-05,\n",
      "          4.4236e-04, -1.6925e-04, -1.3668e-03, -3.4514e-04, -1.1292e-06,\n",
      "         -4.0993e-04,  2.6925e-04,  2.4734e-04,  7.9358e-06,  1.2103e-03,\n",
      "          5.4765e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0019,  0.5201,  0.1847, -0.2228, -0.3589, -0.1002, -0.2560, -0.1883,\n",
      "          0.0290,  0.3542,  0.3235, -0.5812,  0.3679,  0.1660,  0.5617,  0.3913]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -6.161766214063391e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0085], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2786e-04, -4.8742e-04,  8.5516e-05,  1.0490e-03,  8.4987e-05,\n",
      "          4.4241e-04, -1.6917e-04, -1.3670e-03, -3.4500e-04, -1.1943e-06,\n",
      "         -4.0999e-04,  2.6900e-04,  2.4744e-04,  7.9381e-06,  1.2104e-03,\n",
      "          5.4762e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0019,  0.5201,  0.1847, -0.2229, -0.3589, -0.1003, -0.2560, -0.1882,\n",
      "          0.0290,  0.3542,  0.3236, -0.5812,  0.3679,  0.1660,  0.5616,  0.3913]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -7.022300997050479e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0076], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2820e-04, -4.8770e-04,  8.5465e-05,  1.0491e-03,  8.4764e-05,\n",
      "          4.4246e-04, -1.6908e-04, -1.3671e-03, -3.4487e-04, -1.2596e-06,\n",
      "         -4.1004e-04,  2.6875e-04,  2.4754e-04,  7.9405e-06,  1.2105e-03,\n",
      "          5.4758e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0018,  0.5202,  0.1847, -0.2230, -0.3590, -0.1003, -0.2560, -0.1881,\n",
      "          0.0290,  0.3542,  0.3236, -0.5812,  0.3679,  0.1660,  0.5615,  0.3912]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -7.88292963989079e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0067], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2854e-04, -4.8798e-04,  8.5414e-05,  1.0491e-03,  8.4542e-05,\n",
      "          4.4252e-04, -1.6899e-04, -1.3672e-03, -3.4474e-04, -1.3249e-06,\n",
      "         -4.1009e-04,  2.6851e-04,  2.4763e-04,  7.9427e-06,  1.2105e-03,\n",
      "          5.4754e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0018,  0.5202,  0.1847, -0.2231, -0.3590, -0.1004, -0.2559, -0.1879,\n",
      "          0.0291,  0.3542,  0.3236, -0.5812,  0.3678,  0.1660,  0.5613,  0.3911]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -8.743448415771127e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0058], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2888e-04, -4.8825e-04,  8.5363e-05,  1.0492e-03,  8.4319e-05,\n",
      "          4.4257e-04, -1.6891e-04, -1.3674e-03, -3.4460e-04, -1.3901e-06,\n",
      "         -4.1014e-04,  2.6826e-04,  2.4773e-04,  7.9451e-06,  1.2106e-03,\n",
      "          5.4751e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0018,  0.5203,  0.1847, -0.2232, -0.3590, -0.1004, -0.2559, -0.1878,\n",
      "          0.0291,  0.3542,  0.3237, -0.5813,  0.3678,  0.1660,  0.5612,  0.3911]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -9.604135993868113e-05\n",
      "================================================================================\n",
      "previous action tensor([-0.0049], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2922e-04, -4.8853e-04,  8.5312e-05,  1.0493e-03,  8.4096e-05,\n",
      "          4.4262e-04, -1.6882e-04, -1.3675e-03, -3.4447e-04, -1.4556e-06,\n",
      "         -4.1019e-04,  2.6801e-04,  2.4783e-04,  7.9476e-06,  1.2107e-03,\n",
      "          5.4747e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0017,  0.5203,  0.1847, -0.2233, -0.3590, -0.1005, -0.2559, -0.1876,\n",
      "          0.0291,  0.3542,  0.3237, -0.5813,  0.3678,  0.1660,  0.5611,  0.3910]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0001046469114953652\n",
      "================================================================================\n",
      "previous action tensor([-0.0040], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2956e-04, -4.8880e-04,  8.5260e-05,  1.0493e-03,  8.3873e-05,\n",
      "          4.4267e-04, -1.6873e-04, -1.3676e-03, -3.4433e-04, -1.5210e-06,\n",
      "         -4.1024e-04,  2.6776e-04,  2.4793e-04,  7.9500e-06,  1.2108e-03,\n",
      "          5.4743e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0017,  0.5204,  0.1847, -0.2234, -0.3590, -0.1005, -0.2559, -0.1875,\n",
      "          0.0292,  0.3542,  0.3238, -0.5813,  0.3678,  0.1660,  0.5610,  0.3910]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00011325428931741044\n",
      "================================================================================\n",
      "previous action tensor([-0.0031], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.2990e-04, -4.8908e-04,  8.5209e-05,  1.0494e-03,  8.3649e-05,\n",
      "          4.4272e-04, -1.6864e-04, -1.3678e-03, -3.4420e-04, -1.5867e-06,\n",
      "         -4.1029e-04,  2.6751e-04,  2.4803e-04,  7.9525e-06,  1.2109e-03,\n",
      "          5.4739e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0017,  0.5204,  0.1847, -0.2235, -0.3590, -0.1006, -0.2559, -0.1874,\n",
      "          0.0292,  0.3542,  0.3238, -0.5813,  0.3677,  0.1659,  0.5609,  0.3909]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0001218605029862374\n",
      "================================================================================\n",
      "previous action tensor([-0.0022], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3024e-04, -4.8936e-04,  8.5157e-05,  1.0495e-03,  8.3425e-05,\n",
      "          4.4277e-04, -1.6855e-04, -1.3679e-03, -3.4406e-04, -1.6523e-06,\n",
      "         -4.1034e-04,  2.6726e-04,  2.4812e-04,  7.9549e-06,  1.2110e-03,\n",
      "          5.4735e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0016,  0.5205,  0.1847, -0.2237, -0.3590, -0.1006, -0.2559, -0.1872,\n",
      "          0.0292,  0.3542,  0.3239, -0.5814,  0.3677,  0.1659,  0.5607,  0.3909]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00013046750973444432\n",
      "================================================================================\n",
      "previous action tensor([-0.0013], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3058e-04, -4.8963e-04,  8.5105e-05,  1.0495e-03,  8.3201e-05,\n",
      "          4.4281e-04, -1.6846e-04, -1.3680e-03, -3.4393e-04, -1.7180e-06,\n",
      "         -4.1039e-04,  2.6701e-04,  2.4822e-04,  7.9575e-06,  1.2111e-03,\n",
      "          5.4731e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0016,  0.5205,  0.1847, -0.2238, -0.3590, -0.1006, -0.2558, -0.1871,\n",
      "          0.0293,  0.3542,  0.3239, -0.5814,  0.3677,  0.1659,  0.5606,  0.3908]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00013907390530221164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "previous action tensor([-0.0003], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3092e-04, -4.8991e-04,  8.5053e-05,  1.0496e-03,  8.2976e-05,\n",
      "          4.4286e-04, -1.6838e-04, -1.3681e-03, -3.4379e-04, -1.7839e-06,\n",
      "         -4.1044e-04,  2.6676e-04,  2.4832e-04,  7.9600e-06,  1.2111e-03,\n",
      "          5.4727e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0016,  0.5205,  0.1847, -0.2239, -0.3590, -0.1007, -0.2558, -0.1870,\n",
      "          0.0293,  0.3542,  0.3239, -0.5814,  0.3677,  0.1659,  0.5605,  0.3908]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00014768035907763988\n",
      "================================================================================\n",
      "previous action tensor([0.0006], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3126e-04, -4.9018e-04,  8.5001e-05,  1.0496e-03,  8.2752e-05,\n",
      "          4.4291e-04, -1.6829e-04, -1.3682e-03, -3.4365e-04, -1.8498e-06,\n",
      "         -4.1049e-04,  2.6651e-04,  2.4841e-04,  7.9626e-06,  1.2112e-03,\n",
      "          5.4723e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0015,  0.5206,  0.1847, -0.2240, -0.3590, -0.1007, -0.2558, -0.1868,\n",
      "          0.0293,  0.3542,  0.3240, -0.5815,  0.3676,  0.1659,  0.5604,  0.3907]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00015628637629561126\n",
      "================================================================================\n",
      "previous action tensor([0.0015], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3160e-04, -4.9046e-04,  8.4948e-05,  1.0497e-03,  8.2527e-05,\n",
      "          4.4296e-04, -1.6820e-04, -1.3683e-03, -3.4352e-04, -1.9157e-06,\n",
      "         -4.1054e-04,  2.6626e-04,  2.4851e-04,  7.9651e-06,  1.2113e-03,\n",
      "          5.4719e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0015,  0.5206,  0.1846, -0.2241, -0.3590, -0.1008, -0.2558, -0.1867,\n",
      "          0.0294,  0.3542,  0.3240, -0.5815,  0.3676,  0.1659,  0.5603,  0.3907]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.000164892990142107\n",
      "================================================================================\n",
      "previous action tensor([0.0024], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3194e-04, -4.9073e-04,  8.4896e-05,  1.0497e-03,  8.2301e-05,\n",
      "          4.4300e-04, -1.6811e-04, -1.3684e-03, -3.4338e-04, -1.9819e-06,\n",
      "         -4.1059e-04,  2.6600e-04,  2.4861e-04,  7.9678e-06,  1.2114e-03,\n",
      "          5.4714e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0015,  0.5207,  0.1846, -0.2242, -0.3590, -0.1008, -0.2558, -0.1865,\n",
      "          0.0294,  0.3542,  0.3241, -0.5815,  0.3676,  0.1659,  0.5601,  0.3906]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00017349935660604388\n",
      "================================================================================\n",
      "previous action tensor([0.0033], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3228e-04, -4.9101e-04,  8.4843e-05,  1.0498e-03,  8.2076e-05,\n",
      "          4.4305e-04, -1.6802e-04, -1.3685e-03, -3.4324e-04, -2.0479e-06,\n",
      "         -4.1064e-04,  2.6575e-04,  2.4870e-04,  7.9704e-06,  1.2114e-03,\n",
      "          5.4710e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0014,  0.5207,  0.1846, -0.2243, -0.3591, -0.1009, -0.2558, -0.1864,\n",
      "          0.0294,  0.3542,  0.3241, -0.5815,  0.3676,  0.1659,  0.5600,  0.3905]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00018210471898782998\n",
      "================================================================================\n",
      "previous action tensor([0.0042], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3262e-04, -4.9128e-04,  8.4790e-05,  1.0498e-03,  8.1850e-05,\n",
      "          4.4309e-04, -1.6793e-04, -1.3686e-03, -3.4310e-04, -2.1141e-06,\n",
      "         -4.1068e-04,  2.6550e-04,  2.4880e-04,  7.9731e-06,  1.2115e-03,\n",
      "          5.4706e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0014,  0.5208,  0.1846, -0.2244, -0.3591, -0.1009, -0.2557, -0.1863,\n",
      "          0.0295,  0.3542,  0.3241, -0.5816,  0.3675,  0.1659,  0.5599,  0.3905]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00019071082351729274\n",
      "================================================================================\n",
      "previous action tensor([0.0051], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3296e-04, -4.9156e-04,  8.4737e-05,  1.0498e-03,  8.1624e-05,\n",
      "          4.4314e-04, -1.6784e-04, -1.3687e-03, -3.4296e-04, -2.1803e-06,\n",
      "         -4.1073e-04,  2.6524e-04,  2.4890e-04,  7.9759e-06,  1.2116e-03,\n",
      "          5.4701e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0014,  0.5208,  0.1846, -0.2245, -0.3591, -0.1009, -0.2557, -0.1861,\n",
      "          0.0295,  0.3542,  0.3242, -0.5816,  0.3675,  0.1659,  0.5598,  0.3904]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00019931756833102554\n",
      "================================================================================\n",
      "previous action tensor([0.0060], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3330e-04, -4.9183e-04,  8.4684e-05,  1.0499e-03,  8.1398e-05,\n",
      "          4.4318e-04, -1.6775e-04, -1.3688e-03, -3.4283e-04, -2.2467e-06,\n",
      "         -4.1078e-04,  2.6499e-04,  2.4899e-04,  7.9786e-06,  1.2116e-03,\n",
      "          5.4696e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0013,  0.5209,  0.1846, -0.2246, -0.3591, -0.1010, -0.2557, -0.1860,\n",
      "          0.0295,  0.3542,  0.3242, -0.5816,  0.3675,  0.1659,  0.5597,  0.3904]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0002079231635434553\n",
      "================================================================================\n",
      "previous action tensor([0.0069], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3364e-04, -4.9211e-04,  8.4630e-05,  1.0499e-03,  8.1171e-05,\n",
      "          4.4322e-04, -1.6766e-04, -1.3689e-03, -3.4269e-04, -2.3131e-06,\n",
      "         -4.1083e-04,  2.6474e-04,  2.4909e-04,  7.9813e-06,  1.2117e-03,\n",
      "          5.4692e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0013,  0.5209,  0.1846, -0.2247, -0.3591, -0.1010, -0.2557, -0.1859,\n",
      "          0.0296,  0.3542,  0.3243, -0.5816,  0.3675,  0.1659,  0.5595,  0.3903]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.000216528627788648\n",
      "================================================================================\n",
      "previous action tensor([0.0078], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3398e-04, -4.9238e-04,  8.4576e-05,  1.0499e-03,  8.0944e-05,\n",
      "          4.4327e-04, -1.6756e-04, -1.3690e-03, -3.4255e-04, -2.3795e-06,\n",
      "         -4.1087e-04,  2.6448e-04,  2.4919e-04,  7.9841e-06,  1.2117e-03,\n",
      "          5.4687e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0013,  0.5210,  0.1846, -0.2248, -0.3591, -0.1011, -0.2557, -0.1857,\n",
      "          0.0296,  0.3542,  0.3243, -0.5817,  0.3674,  0.1659,  0.5594,  0.3903]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00022513358271680772\n",
      "================================================================================\n",
      "previous action tensor([0.0087], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3432e-04, -4.9265e-04,  8.4523e-05,  1.0500e-03,  8.0717e-05,\n",
      "          4.4331e-04, -1.6747e-04, -1.3691e-03, -3.4241e-04, -2.4460e-06,\n",
      "         -4.1092e-04,  2.6423e-04,  2.4928e-04,  7.9869e-06,  1.2118e-03,\n",
      "          5.4682e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0012,  0.5210,  0.1846, -0.2249, -0.3591, -0.1011, -0.2557, -0.1856,\n",
      "          0.0297,  0.3542,  0.3243, -0.5817,  0.3674,  0.1659,  0.5593,  0.3902]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00023373801377601922\n",
      "================================================================================\n",
      "previous action tensor([0.0096], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3466e-04, -4.9293e-04,  8.4469e-05,  1.0500e-03,  8.0490e-05,\n",
      "          4.4335e-04, -1.6738e-04, -1.3692e-03, -3.4227e-04, -2.5126e-06,\n",
      "         -4.1096e-04,  2.6397e-04,  2.4938e-04,  7.9898e-06,  1.2118e-03,\n",
      "          5.4677e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0012,  0.5211,  0.1846, -0.2250, -0.3591, -0.1012, -0.2556, -0.1855,\n",
      "          0.0297,  0.3542,  0.3244, -0.5817,  0.3674,  0.1659,  0.5592,  0.3902]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -0.0002423423429718241\n",
      "================================================================================\n",
      "previous action tensor([0.0105], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3500e-04, -4.9320e-04,  8.4414e-05,  1.0500e-03,  8.0262e-05,\n",
      "          4.4339e-04, -1.6729e-04, -1.3693e-03, -3.4213e-04, -2.5793e-06,\n",
      "         -4.1101e-04,  2.6371e-04,  2.4947e-04,  7.9927e-06,  1.2119e-03,\n",
      "          5.4672e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0012,  0.5211,  0.1846, -0.2251, -0.3591, -0.1012, -0.2556, -0.1853,\n",
      "          0.0297,  0.3542,  0.3244, -0.5817,  0.3674,  0.1659,  0.5590,  0.3901]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0002509458572603762\n",
      "================================================================================\n",
      "previous action tensor([0.0114], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3534e-04, -4.9347e-04,  8.4360e-05,  1.0501e-03,  8.0034e-05,\n",
      "          4.4344e-04, -1.6720e-04, -1.3694e-03, -3.4198e-04, -2.6460e-06,\n",
      "         -4.1105e-04,  2.6346e-04,  2.4957e-04,  7.9955e-06,  1.2119e-03,\n",
      "          5.4667e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0011,  0.5212,  0.1846, -0.2252, -0.3591, -0.1013, -0.2556, -0.1852,\n",
      "          0.0298,  0.3542,  0.3245, -0.5818,  0.3673,  0.1659,  0.5589,  0.3901]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0002595494734123349\n",
      "================================================================================\n",
      "previous action tensor([0.0123], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3568e-04, -4.9375e-04,  8.4305e-05,  1.0501e-03,  7.9806e-05,\n",
      "          4.4348e-04, -1.6711e-04, -1.3695e-03, -3.4184e-04, -2.7129e-06,\n",
      "         -4.1110e-04,  2.6320e-04,  2.4966e-04,  7.9984e-06,  1.2120e-03,\n",
      "          5.4662e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0011,  0.5212,  0.1845, -0.2253, -0.3591, -0.1013, -0.2556, -0.1850,\n",
      "          0.0298,  0.3542,  0.3245, -0.5818,  0.3673,  0.1659,  0.5588,  0.3900]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00026815166347660124\n",
      "================================================================================\n",
      "previous action tensor([0.0132], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3602e-04, -4.9402e-04,  8.4251e-05,  1.0501e-03,  7.9577e-05,\n",
      "          4.4352e-04, -1.6701e-04, -1.3695e-03, -3.4170e-04, -2.7797e-06,\n",
      "         -4.1114e-04,  2.6294e-04,  2.4976e-04,  8.0013e-06,  1.2120e-03,\n",
      "          5.4657e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0011,  0.5213,  0.1845, -0.2254, -0.3591, -0.1013, -0.2556, -0.1849,\n",
      "          0.0298,  0.3542,  0.3245, -0.5818,  0.3673,  0.1659,  0.5587,  0.3899]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0002767551050055772\n",
      "================================================================================\n",
      "previous action tensor([0.0141], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3636e-04, -4.9429e-04,  8.4196e-05,  1.0501e-03,  7.9349e-05,\n",
      "          4.4355e-04, -1.6692e-04, -1.3696e-03, -3.4156e-04, -2.8467e-06,\n",
      "         -4.1119e-04,  2.6269e-04,  2.4985e-04,  8.0042e-06,  1.2121e-03,\n",
      "          5.4652e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0010,  0.5213,  0.1845, -0.2255, -0.3592, -0.1014, -0.2556, -0.1848,\n",
      "          0.0299,  0.3542,  0.3246, -0.5818,  0.3673,  0.1659,  0.5586,  0.3899]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00028535729506984353\n",
      "================================================================================\n",
      "previous action tensor([0.0150], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3670e-04, -4.9457e-04,  8.4141e-05,  1.0501e-03,  7.9120e-05,\n",
      "          4.4359e-04, -1.6683e-04, -1.3697e-03, -3.4142e-04, -2.9137e-06,\n",
      "         -4.1123e-04,  2.6243e-04,  2.4995e-04,  8.0073e-06,  1.2121e-03,\n",
      "          5.4646e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0010,  0.5214,  0.1845, -0.2256, -0.3592, -0.1014, -0.2555, -0.1846,\n",
      "          0.0299,  0.3542,  0.3246, -0.5819,  0.3672,  0.1659,  0.5584,  0.3898]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00029395840829238296\n",
      "================================================================================\n",
      "previous action tensor([0.0159], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3704e-04, -4.9484e-04,  8.4086e-05,  1.0502e-03,  7.8890e-05,\n",
      "          4.4363e-04, -1.6674e-04, -1.3698e-03, -3.4127e-04, -2.9808e-06,\n",
      "         -4.1127e-04,  2.6217e-04,  2.5004e-04,  8.0102e-06,  1.2122e-03,\n",
      "          5.4641e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0010,  0.5214,  0.1845, -0.2258, -0.3592, -0.1015, -0.2555, -0.1845,\n",
      "          0.0299,  0.3542,  0.3247, -0.5819,  0.3672,  0.1659,  0.5583,  0.3898]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00030255960882641375\n",
      "================================================================================\n",
      "previous action tensor([0.0168], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3738e-04, -4.9511e-04,  8.4031e-05,  1.0502e-03,  7.8661e-05,\n",
      "          4.4367e-04, -1.6664e-04, -1.3698e-03, -3.4113e-04, -3.0480e-06,\n",
      "         -4.1132e-04,  2.6191e-04,  2.5014e-04,  8.0133e-06,  1.2122e-03,\n",
      "          5.4635e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0009,  0.5215,  0.1845, -0.2259, -0.3592, -0.1015, -0.2555, -0.1844,\n",
      "          0.0300,  0.3542,  0.3247, -0.5819,  0.3672,  0.1659,  0.5582,  0.3897]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00031115958699956536\n",
      "================================================================================\n",
      "previous action tensor([0.0177], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3772e-04, -4.9538e-04,  8.3975e-05,  1.0502e-03,  7.8431e-05,\n",
      "          4.4371e-04, -1.6655e-04, -1.3699e-03, -3.4099e-04, -3.1152e-06,\n",
      "         -4.1136e-04,  2.6165e-04,  2.5023e-04,  8.0164e-06,  1.2122e-03,\n",
      "          5.4630e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0009,  0.5215,  0.1845, -0.2260, -0.3592, -0.1016, -0.2555, -0.1842,\n",
      "          0.0300,  0.3542,  0.3248, -0.5820,  0.3672,  0.1659,  0.5581,  0.3897]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0003197581972926855\n",
      "================================================================================\n",
      "previous action tensor([0.0186], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3806e-04, -4.9565e-04,  8.3919e-05,  1.0502e-03,  7.8201e-05,\n",
      "          4.4374e-04, -1.6646e-04, -1.3700e-03, -3.4084e-04, -3.1825e-06,\n",
      "         -4.1140e-04,  2.6139e-04,  2.5033e-04,  8.0194e-06,  1.2122e-03,\n",
      "          5.4624e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0009,  0.5216,  0.1845, -0.2261, -0.3592, -0.1016, -0.2555, -0.1841,\n",
      "          0.0300,  0.3542,  0.3248, -0.5820,  0.3671,  0.1659,  0.5580,  0.3896]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.000328357913531363\n",
      "================================================================================\n",
      "previous action tensor([0.0195], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3840e-04, -4.9593e-04,  8.3864e-05,  1.0502e-03,  7.7971e-05,\n",
      "          4.4378e-04, -1.6636e-04, -1.3700e-03, -3.4070e-04, -3.2498e-06,\n",
      "         -4.1144e-04,  2.6113e-04,  2.5042e-04,  8.0225e-06,  1.2123e-03,\n",
      "          5.4619e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0008,  0.5216,  0.1845, -0.2262, -0.3592, -0.1017, -0.2555, -0.1839,\n",
      "          0.0301,  0.3542,  0.3248, -0.5820,  0.3671,  0.1659,  0.5578,  0.3896]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.0003369573096279055\n",
      "================================================================================\n",
      "previous action tensor([0.0204], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3874e-04, -4.9620e-04,  8.3808e-05,  1.0502e-03,  7.7740e-05,\n",
      "          4.4382e-04, -1.6627e-04, -1.3701e-03, -3.4055e-04, -3.3172e-06,\n",
      "         -4.1149e-04,  2.6087e-04,  2.5052e-04,  8.0256e-06,  1.2123e-03,\n",
      "          5.4613e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0008,  0.5217,  0.1845, -0.2263, -0.3592, -0.1017, -0.2554, -0.1838,\n",
      "          0.0301,  0.3542,  0.3249, -0.5820,  0.3671,  0.1659,  0.5577,  0.3895]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The loss of training is -0.0003455550177022815\n",
      "================================================================================\n",
      "previous action tensor([0.0213], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3908e-04, -4.9647e-04,  8.3751e-05,  1.0502e-03,  7.7510e-05,\n",
      "          4.4385e-04, -1.6617e-04, -1.3701e-03, -3.4041e-04, -3.3848e-06,\n",
      "         -4.1153e-04,  2.6061e-04,  2.5061e-04,  8.0288e-06,  1.2123e-03,\n",
      "          5.4607e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0008,  0.5217,  0.1845, -0.2264, -0.3592, -0.1017, -0.2554, -0.1837,\n",
      "          0.0301,  0.3542,  0.3249, -0.5821,  0.3671,  0.1659,  0.5576,  0.3895]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00035415092133916914\n",
      "================================================================================\n",
      "previous action tensor([0.0223], grad_fn=<TanhBackward>)\n",
      "tensor([[-3.3942e-04, -4.9674e-04,  8.3695e-05,  1.0502e-03,  7.7279e-05,\n",
      "          4.4388e-04, -1.6608e-04, -1.3702e-03, -3.4026e-04, -3.4521e-06,\n",
      "         -4.1157e-04,  2.6034e-04,  2.5071e-04,  8.0320e-06,  1.2123e-03,\n",
      "          5.4601e-04]])\n",
      "******weights******\n",
      "tensor([[-0.0007,  0.5218,  0.1844, -0.2265, -0.3592, -0.1018, -0.2554, -0.1835,\n",
      "          0.0302,  0.3542,  0.3250, -0.5821,  0.3670,  0.1659,  0.5575,  0.3894]])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "<class 'torch.Tensor'>\n",
      "torch.Size([])\n",
      "The loss of training is -0.00036274734884500504\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "T = 3602\n",
    "m = 10\n",
    "to_draw = np.sort(Pad['timestamp'].unique())\n",
    "ccy = np.sort(Pad['currency pair'].unique())\n",
    "min_history = 500 # min episode length\n",
    "\n",
    "    \n",
    "def generate_episode(n,cur):\n",
    "    _max = to_draw.shape[0]\n",
    "    _end = min(n+T, _max)\n",
    "    timeframe = to_draw[n:_end]\n",
    "    other_bid = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    other_ask = np.zeros((timeframe.shape[0],ccy.shape[0]-1))\n",
    "    i = 0\n",
    "    for elem in ccy:\n",
    "        tmp = Pad[Pad['currency pair'] == elem]\n",
    "        if elem == cur:\n",
    "            target_bid = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            target_ask = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "        else:\n",
    "            other_bid[:,i] = tmp[tmp.timestamp.isin(timeframe)]['bid price'].values\n",
    "            other_ask[:,i] = tmp[tmp.timestamp.isin(timeframe)]['ask price'].values\n",
    "            i += 1\n",
    "    return target_bid, target_ask, other_bid, other_ask\n",
    "\n",
    "def features(price_path,m):\n",
    "    features = np.zeros((price_path.shape[0]-m,m))\n",
    "    for i in range(m):\n",
    "        features[:,i] = (np.log(price_path) - np.log(np.roll(price_path, i+1)))[m:]\n",
    "    return features\n",
    "\n",
    "def get_features(target_bid, target_ask, other_bid, other_ask, m):\n",
    "    feature_span = features(target_bid,m)\n",
    "    feature_span = np.append(feature_span, features(target_ask,m), axis = 1)\n",
    "    for i in range(other_bid.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_bid[:,i],m), axis = 1)\n",
    "    for j in range(other_ask.shape[1]):\n",
    "        feature_span = np.append(feature_span, features(other_ask[:,j],m), axis = 1)\n",
    "    return feature_span\n",
    "\n",
    "def draw_episode(m, cur, min_history):\n",
    "    '''\n",
    "    Input:\n",
    "        m, number of lag returns z_1,...z_m\n",
    "        cur, currency pair that we target to trade\n",
    "        min_history, min length of a valid episode\n",
    "    '''\n",
    "    n = np.random.randint(to_draw.shape[0] - min_history)\n",
    "    n = 5000\n",
    "    target_bid, target_ask, other_bid, other_ask = generate_episode(n,cur)\n",
    "    feature_span = get_features(target_bid, target_ask, other_bid, other_ask, m)\n",
    "    normalized = (feature_span-feature_span.mean())/feature_span.std()\n",
    "    return target_bid, target_ask, normalized\n",
    "import gym\n",
    "import gym_banana\n",
    "import argparse\n",
    "import numpy as np\n",
    "from itertools import count\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions import Categorical\n",
    "from torch.autograd import Variable\n",
    "\n",
    "\n",
    "#parser = argparse.ArgumentParser(description='PyTorch REINFORCE example')\n",
    "# parser.add_argument('--gamma', type=float, default=0.99, metavar='G',\n",
    "#                     help='discount factor (default: 0.99)')\n",
    "# parser.add_argument('--seed', type=int, default=543, metavar='N',\n",
    "#                     help='random seed (default: 543)')\n",
    "# parser.add_argument('--render', action='store_true',\n",
    "#                     help='render the environment')\n",
    "# parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "#                     help='interval between training status logs (default: 10)')\n",
    "#args = parser.parse_args()\n",
    "\n",
    "\n",
    "env = gym.make('Banana-v0')\n",
    "env.seed(1)\n",
    "torch.manual_seed(1)\n",
    "\n",
    "\n",
    "class Policy(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Policy, self).__init__()\n",
    "        self.affine1 = nn.Linear(16, 1, bias = True)\n",
    "#         self.A = Variable(torch.randn(256, 3), requires_grad=True)\n",
    "#         self.b = Variable(torch.randn(1), requires_grad=True)\n",
    "        torch.nn.init.xavier_uniform(self.affine1.weight)\n",
    "        #print('The weight of the affine layer is', self.affine1.weight)\n",
    "#         self.dropout = nn.Dropout(p=0)\n",
    "#        self.mu = Variable(torch.randn(3, 3), requires_grad=True)\n",
    "        #self.mu = nn.Linear(1,3, bias = True)\n",
    "                #torch.nn.init.xavier_uniform(self.affine1.weight)\n",
    "        #print('The weight of the affine layer is', self.affine1.weight)\n",
    "        # self.tanh = nn.Tanh()\n",
    "        self.tanh = nn.Tanh()\n",
    "\n",
    "        self.saved_log_probs = []\n",
    "        self.rewards = 0\n",
    "        self.actions = []\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.affine1(x)\n",
    "#         x = torch.matmul(x, self.A) \n",
    "#         x = self.dropout(x)\n",
    "#         print(x.size())\n",
    "        #mu_sigma = torch.matmul(y, self.mu)\n",
    "#         print(mu_sigma.size())\n",
    "        # action = self.tanh(x + mu_sigma)\n",
    "        # action = self.softmax(action)\n",
    "        action = self.tanh(x)\n",
    "#         action_scores = self.affine2(x)\n",
    "#         return F.softmax(action_scores, dim=1)\n",
    "        return action\n",
    "\n",
    "\n",
    "global policy\n",
    "policy = Policy()\n",
    "\n",
    "optimizer = optim.SGD(policy.parameters(), lr=1e-1)\n",
    "eps = np.finfo(np.float32).eps.item()\n",
    "\n",
    "\n",
    "# def select_action(state, previous_action):\n",
    "#     state = torch.from_numpy(state).float()\n",
    "#     previous_action = previous_action\n",
    "#     probs = policy(state, previous_action)\n",
    "    #return probs\n",
    "    #m = Categorical(probs)\n",
    "    #action = m.sample()\n",
    "    #policy.saved_log_probs.append(m.log_prob(action))\n",
    "#     return probs.detach().numpy()\n",
    "    #return action.item() - 1\n",
    "\n",
    "\n",
    "def finish_episode(num):\n",
    "    R = 0\n",
    "    policy_loss = []\n",
    "    returns = []\n",
    "#     for r in policy.rewards[::-1]:\n",
    "#         #print(\"reward\",r * 1000000)\n",
    "# #         R = r\n",
    "#         returns.insert(0, R)\n",
    "#     returns = torch.tensor(returns)\n",
    "#     optimizer.zero_grad()\n",
    "#     # returns = (returns - returns.mean()) / (returns.std() + eps)\n",
    "#     for R in returns:\n",
    "# #         print(Variable(-torch.ones(log_prob.shape), requires_grad = True) * R)\n",
    "#         #print(\"return\", R)\n",
    "#         #print(\"policy_append\", Variable(-torch.ones(log_prob.shape) * 1000000, requires_grad = True) * R)\n",
    "#         #policy_loss.append( torch.tensor(-1000000* R))\n",
    "#         policy_loss.append(Variable(-torch.ones((1,)) * 1000000, requires_grad = True) * R)\n",
    " \n",
    "#     policy_loss = torch.cat(policy_loss).sum() \n",
    "#     #policy_loss = policy.A.sum()\n",
    "#     policy_loss.backward()\n",
    "#     optimizer.step()\n",
    "#     print(policy.A.grad)\n",
    "#     #print(policy.b.grad)\n",
    "#     #print(list(policy.parameters()))\n",
    "#     print (\"Finished {} episode and the policy loss is {}\".format(num, policy_loss))\n",
    "#     policy.rewards = []\n",
    "    #optimizer.zero_grad()\n",
    "    #del policy.saved|_log_probs[:]\n",
    "    print(policy.A.grad)\n",
    "    print(policy.b.grad)\n",
    "    loss = policy.A.sum()\n",
    "    loss.backward()\n",
    "    policy.rewards.backward()\n",
    "    optimizer.step()\n",
    "    optimizer.zero_grad()\n",
    "    \n",
    "\n",
    "\n",
    "def main():\n",
    "    for i_episode in range(100):\n",
    "        ask = np.zeros((1, 1))\n",
    "        bid = np.zeros((1,1 ))\n",
    "        previous_action = np.array([0, 0, 1])\n",
    "        while ask.shape[0] <= 3600 and bid.shape[0]<=3600:\n",
    "            target_bid, target_ask, feature_span = draw_episode(1, 'AUDUSD', 1000)\n",
    "            bid, ask, features = target_bid[1:]*1e3, target_ask[1:]*1e3, feature_span\n",
    "        for t in range(3600):  # Don't infinite loop while learning\n",
    "            state = feature_span[t]\n",
    "#             action = select_action(state, previous_action)\n",
    "            action = policy(torch.from_numpy(state).float())\n",
    "#             print('The action chosen at the current step is {}'.format(action))\n",
    "#             action = Variable(action, requires_grad=True)\n",
    "#             reward = ((action) * (ask[t+1] - ask[t]) + (bid[t+1] - bid[t]))\n",
    "#             reward = Variable(torch.tensor([reward.sum()]), requires_grad=True)\n",
    "            price_change = (ask[t] - ask[t+1]) + (bid[t] - bid[t+1])\n",
    "#             print ('The price change is {}'.format(price_change))\n",
    "#             print('A preview of price change {}'.format(after_mask * price_change))\n",
    "            reward = torch.sum(action * price_change)\n",
    "#             print('what we can get {}'.format(reward.float().item()))\n",
    "#             print('The price chance at this time step is {}'.format(price_change))\n",
    "            \n",
    "            policy.rewards += reward\n",
    "#             print('The cumulative reward so far is {}'.format(policy.rewards))\n",
    "#             ep_reward += reward\n",
    "            #policy.actions.append(action)\n",
    "            previous_action = action\n",
    "\n",
    "\n",
    "        \n",
    "#         running_reward = 0.05 * ep_reward + (1 - 0.05) * running_reward\n",
    "#         finish_episode(i_episode)\n",
    "#         print(policy.A.grad)\n",
    "#         print(policy.b.grad)\n",
    "        print(80*'=')\n",
    "        print ('previous action {}'.format(previous_action))\n",
    "        if policy.affine1.weight.grad is not None:\n",
    "            print(policy.affine1.weight.grad)\n",
    "            print('******weights******')\n",
    "            print(policy.affine1.weight.data)\n",
    "#         policy.rewards.backward()\n",
    "#         loss = policy.A.sum()\n",
    "        optimizer.zero_grad()\n",
    "        loss = - policy.rewards / 3600\n",
    "        print (type(loss))\n",
    "        print(loss.size())\n",
    "        print(type(policy.rewards))\n",
    "        print(torch.sum(policy.rewards).size())\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "        print('The loss of training is {}'.format(loss.item()))\n",
    "        policy.rewards = 0\n",
    "#         optimizer.zero_grad()\n",
    "#         if i_episode % 5 == 0:\n",
    "#             print('Episode {}\\tLast reward: {:.2f}\\tAverage reward: {:.2f}'.format(\n",
    "#                   i_episode, ep_reward, running_reward))\n",
    "#         if running_reward > env.spec.reward_threshold:\n",
    "#             print(\"Solved! Running reward is now {} and \"\n",
    "#                   \"the last episode runs to {} time steps!\".format(running_reward, t))\n",
    "#             break\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
